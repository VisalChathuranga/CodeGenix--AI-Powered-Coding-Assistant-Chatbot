
=== Page 1 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd
ROS+OpenCV Course




=== Page 2 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Catalog
1. Color Threshold Adjustment .......... cc ccc cece eee cece eee cece enna
1.1 Open/Close LAB TOOL ....... cee ec cece ccc ee eee ee eee eee
1.2 LAB TOOL Interface Layout Instruction ........ 0... cee cece ee eee eee
1.3 Adjust Color Threshold ......... cece cece ec cece eee eens
1.4 Add New Color 2... ccc ccc cc ccc ccc cee cece eee cee eee eee eees 10
2. Color RECOGNITION 2... cece cee eect eee eee eee e eee eeee 12
2.1 Recognition Process ...... cee cece ec ee eee ee ee eee eee eee 12
2.2 Operation StepS .... cece ccc eee ee ee ee eee eee tenes 13
2.3 Program OutCOMe ...... cee cece eee eee cece eee eee eees 14
2.4 Program AnalySis ........ cece eee cece eee cere cece eee eee eeees 15
2.4.1 Main Function 2... .... ccc cece ee ee cece eee eter ee eens 16
2.4.2 Image ProceSSiNg ....... cece cece eee eee eee eee eee eee teens 16
3. Generate & Recognize QR Code 2... ccc ccc ccc ccc ee cee eee e en eees 18
3.1 Generate QR Code 2... ccc ccc eect e ee eee ee eens 18
3.1.1 PFOCESS 2... cece ce ccc ee eee eee eee eee eee eee eee e eee 18
3.1.2 Operation StepS 2... ce cc cc eee cee eee eee ee ees 19
3.1.3 Program Analysis ........ cece cece eee eee eect ee eee eens 21
3.2 QR Code Recognition ........ cece ccc cece cee cette eens 23
3.2.1 Recognition Process ...... ec cee ee ccc ee eee cette reece eens 24
3.2.2 QR Code Recognition Steps ... 2... cece eee ec eee eee eee eee 24
4. Autonomous Line Following .......... eee cc eee eee wee eee eee e eens 28



=== Page 3 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

4.1 Recognition Procedure ....... ccc ce ec cece ee eeee ee eee tees 28
4.2 Autonomous Line Following Operation ........... 20. ce eee ee ee eens 29
4.3 Program AnalySis ........ cece ccc cee cee cece eee cette ee eee cece 30

1. Color Threshold Adjustment

The color of an object can change with the light sources, which can affect the
functionality involved color recognition. To tackle this issue, this lesson will

introduce you how to use LAB Tool to adjust the color threshold.

1.1 Open/Close LAB TOOL

Note:

1) The entered command should be case sensitive, and the “Tab” key can be

used to complement key words.

2) Please strictly follow the operation steps; otherwise, you will fail to open

LAB tool.

During the color adjustment process, all steps are executed within the ROS1

environment.

1) Start the robot and connect it to NoMachine remote connection
software.

2) Click on lo to open the ROS1 command line terminal.

3) Input the command and press Enter to disable app auto-start service.

sudo systemctl stop start_app_node.service

stop start_app_node.service

4) Input the command and press Enter to enable the camera service

3



=== Page 4 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

node.
Depth camera:

ros2 launch peripherals depth_camera.launch.py

peripherals depth camera, launch.

Launch

Monocular Camera

ros2 launch peripherals usb_cam.launch.py

5) Open a new command-line terminal and input the command to open

LAB tool, then hit Enter key.

python3 /home/ubuntu/software/lab_tool/main.py

LAB_Tool 1.0

0 a— eel

i | x
A Fai] 0 fia | ©3255 © English
ce | o 8 ES 255

LAB is composed of one lightness channel and two color channels. And each color is represented by
three values, including L, Aand B
Lrefers to lightness
- A*refers to the components from green to red
- B*refers to the components from blue to yellow

6) Regarding the interface button instructions and usage, you can refer to

the following content. If you want to close it, please click on Quit.



=== Page 5 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

7) After closing LAB tool, input the command to restart app auto-start

service. After the service is enable, robot arm will restore the initial position.
sudo systemctl restart start_app_node.service

stop start_app_node.service

Note: if you do not enable app auto-start service for the robot, it will affect the
corresponding app functions. Restarting robot can also automatically enable

the app auto-start service.
1.2 LAB TOOL Interface Layout Instruction

The interface of LAB tool software is divided into two parts: image display area

and recognition adjustment area.



=== Page 6 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

LAB_Tool 1.0

0 [=] VK 90 ™ Color list cas
o 255
o 8 255

LAB is composed of one lightness channel and two color channels. And each color is represented by | Delete

© English

three values, including L, AandB
L*refers to lightness
- A*refers to the components from green to red
- B*refers to the components from blue to yellow

1) Image display area: the left displays the processed image and the right is

the raw image.

Note: if the transmitted image does not display normally, it’s the issue of camera
connection. In this case, you need to examine if the wiring is connected properly or

reconnect it.

2) Recognition adjustment area: adjust the color threshold. The function of

each button refer to the following table:

The sliders L, Aand B are used respectively to adjust
the values of the corresponding L, Aand B

components of the image.

a 80 = fF 89
ag og Gi 2ss
ce | Gog +B

The sliders on the left are the “min” value for each
component while the slider on the right are the “max”

value for each component.




=== Page 7 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Choose color to adjust the threshold.

Delete Delete the currently selected color.

Ada Add recognizable color.

Save the adjustment result of the color threshold.

Click on this button to swap Depth

camera/monocular camera.

Close LAB TOOL.

J)
a
-

1.3 Adjust Color Threshold

1) Open LAN tool. Choose the color in the color drop-down list of color

recognition area. Take a color “red” as example.

Color list

2) Adjust the “min” values of L, A and B components to “0”, the “max”

values to “225”.

3) Place the target within the camera’s field of view. Adjust the values of L,



=== Page 8 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

A and B component towards the interval representing the target recognition

color according to the LAB color space distribution chart.

* Whit

i & Red

© & Blact

Red color is close to “+a”, which indicates that A component needs to be
increased. Therefore, keep the “max” value of the A component unchanged
and increase its “min” value until the object on the left turns white while other

areas turn black.

255
255
255

4) Adjust the Land B components according to your surroundings. If the

red color is light, increase the “min” value of the L component; if it is dark,

8



=== Page 9 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

decrease the “max” value of the component. If the red color tends to be warm,
increase the "min" value of the B component; if it tends to be cool, decrease

the "max" value of the B component.

The following table shows the parameter information of LAB threshold

adjustment:
L 0~255 Black-white (-L~+L)
A 0~255 green-red (-a ~ +a)
B 0~255 Blue-yellow (-b ~ +b)

5) Click “Save” button in adjustment area to save the adjustment

parameters.

Color list




=== Page 10 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

1.4 Add New Color

In addition to the built-in colors, users can add other recognition colors. Take

an example of adding “yellow”.

1) Open LAB tool and click on “Add” button.

Color list

2) Fill in the "name" column with the color name, and click the "OK"

button.

name yellow

Cancel OK

3) Choose the added color in the color drop-down menu.

10



=== Page 11 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Color list

Add

Delete

2AaVE

4) Place the target within the camera's field of view, and adjust the
threshold by dragging the L, A, and B component sliders until the area of the
colored object within the left screen turns white, while the other areas turn

black.

| 0  —_—_ man ff" 200
AB o FS 255
ce — el 155 | = | FS 255

Note: the adjustment method of color threshold refers to “1.3 Adjust

Color Adjustment”.

5) Click “Save” button in recognition adjustment area to save the

adjustment parameters of color threshold.

11



=== Page 12 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Color list chy

® English

Ada

After adjusting the color thresholds, press 'Ctrl+C' to close the camera service,

and then click 'Quit' to exit the interface.

2. Color Recognition

This session will use OpenCV to perform red, green, blue recognition and
display the recognition result through transmitted image. Before operations,

please prepare one object of red, green and blue.
2.1 Recognition Process

Firstly, obtain the RGB image from the camera. Scale and apply Gaussian blur
to the image. Convert the image from RGB to Lab. (For detailed explanations
regarding the Lab color space, you can refer to "1. Tutorials\ 2. Basic

Development Course\ 3. OpenCV Basic Course".)

Next, identify the object color in the circle by using color thresholds, followed
by masking of the image portion. (masking is used to hide certain part of the

processed image).

After performing opening and closing operations on the object image, the

object with the largest contour is circled.

12



=== Page 13 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Open operations: erosion followed by dilation. Remove small objects, smooth
the contours of object and keep its area unchanged. It can eliminate small

noise and break thin connection between objects.

Erosion: it can be used to remove small objects or features from an image,
break thin connections between objects, and generally reduce the size of

objects.

Dilation: it is useful for filling in gaps between objects, joining nearby objects,

and generally increasing the size of objects.

Finally, the recognition results are displayed on the screen.

2.2 Operation Steps

Note: the entered command should be case sensitive and “Tab” key can

be used to complement the key words.

1) Start the robot and connect it to Nomachine.

2) Click on lo to start the command line terminal.

3) Input the command and press Enter to disable the app auto-start

service.
sudo systemctl stop start_app_node.service
4) Run the following command to start the depth camera node.

ros2 launch peripherals depth_camera.launch.py

launch peripherals depth_camera.launch.py

5) Create a new command-line terminal, and enter the following



=== Page 14 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

command to navigate to the program directory and start the color detection

game:

cd ~/ros2_ws/src/example/example/color_detect && python3

color_detect_demo.py

6) The program will launch the camera's image interface. For detailed

recognition steps, please refer to section 2.3 Program Outcome.

7) Next, press "Ctrl+C" in the command line terminal interface. If closing

fails, please try again repeatedly.

2.3 Program Outcome

Note: after the game starts, please ensure that there are no other objects containing
recognized colors within the field of view of the camera to avoid affecting the

implementation effect.

After the game starts, place the target object within the field of view of the
camera. When recognizing the target object, it will be circled up in the same
color and the color name will be printed in the lower-left corner of the screen.

The program supports red, blue and green object recognition.

14



=== Page 15 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

image

a

(x=162, y=167) — R:140 6 196 B:135
2.4 Program Analysis

The source code of the program is located in

/home/ubuntu/ros2_ws/src/example/scripts/color_detect/color_detect_d

emo.py
main Main function
; image callback Image callback function
color dete Bt: demo 1°)’auy Function , run Color recognition function
L : " Maximum contour

getAreaMaxContour getting function —

yaml function
get_yaml_data ____feading function

f get_yaml_data
r f open

15



=== Page 16 ===
HIVVE9MCOCT Shenzhen Hiwonder Technology Co,Ltd

2.4.1 Main Function
@ Main Function

Initialize the ROS node, create a color recognition node named
"“color_detect_node", subscribe to the image topic
"[depth_cam/rgb/image_raw", and set its callback function to
"image_callback". Start the main function for color recognition using multiple

threads. Wait for the node to shut down.

2.4.2 Image Processing

@ Camera Callback Function

Primarily used to read the video stream from the topic and enqueue it to

ensure real-time display.

@ Color Recognition Main Function

Reads image information from the queue and inputs it into the “run* function to

obtain the color-recognized image. Finally, it uses “cv2° to display the image.

16



=== Page 17 ===
@ Read YAML File Function

27 def get_yaml_data(yaml_file):
\ File open

@ Largest Contour Function

Inputs contours identified by OpenCV, determines the largest contour based

on size, and returns the contour and its area.

38 # Fe mAR
39 # SBRALBILS
40 def getAreaMaxConto
41 contour_area_temp =
44
# AMPA A Hm

MRAF Soh, MAMRMNMMS BAX

return area_max_contour, contour_area_max # iREIMAHIFEES

@ Color Recognition Function

Inputs an image, resizes it to a parameter size (320, 240) for easier detection,

applies Gaussian processing, and converts the image to the LAB color space.

59 def run(im

60 global d

61 global c i

62 global detect_color

# TARP A LaBS

et i EE (e F0  HH 1F in He

The function loops through the color list for color recognition, outputting the

color of the largest detected contour.

17



=== Page 18 ===
Contours with an area less than 200 are filtered out. If the area is greater than
200, it calculates the contour coordinates and highlights the position of the

target color in the image based on the largest contour.

3. Generate & Recognize QR Code

This lesson is divided into two parts. The first part will introduce you how to
learn to create a QR code, while the second part focuses on recognizing the
created QR code and then decoding the QR code information through the

terminal.

3.1 Generate QR Code

3.1.1 Process

First, create an instance object of the QR code tool and set its detailed

parameters.

18



=== Page 19 ===
HSI W/EQXMOCT Shenzhen Hiwonder Technology Co,Ltd

Next, obtain the user’s data and fill it into the QR code.

Finally, generate a QR CODE image based on the data and display it in a

window, and save it in the corresponding path.

3.1.2 Operation Steps

Note: the entered command should be case sensitive and the “Tab” key can be

used to fill in key words.

1) Start the robot and connect it to Nomachine.

2) Click on lo to open the command line terminal.
3) Input the command and press Enter to disable the app auto-start service.
sudo systemctl stop start_app_node.service

stop start_app_node.service

4) Input the command to access the program directory and start the QR code

creation program.

cd ~/ros2_ws/src/example/example/qrcode && python3

qrcode_creater.py

After start the program, it’s necessary to enter characters in the terminal to

generate the QR code. Take the input of “ubuntu” as example.

Press “Enter” to display a QR code image containing the input data.

19



=== Page 20 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

GHaaovoaeoaga e888

Oye |
[=] :

5) Next, press the ESC key or the 'q' key to exit the QR code window.

6) When you return to the command line terminal, if you see the prompt

message shown in the image below, it means the QR code has been

successfully saved and generated.

save ubuntu /home/ubuntu/ros2_ws/src/example/example/qrcode/myQRcode. jpg

7) Next, click on to open the file manager. Navigate to the directory
highlighted in red in the image below, where you will find the generated QR

code exported to the host system.

qrcode

Recent ‘ORaG

* Starred I) e @
myQRcode qrcode_ qrcode_

fat Home jpg creater.py detecter.py

(© Desktop

(2) Documents

& Downloads

8) You can then drag the image to your PC desktop using the NoMachine tool,

and print it or transfer it to your phone's photo gallery.

20



=== Page 21 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Jan1 08:22

f qrcode
a
3 ® &

myQRcode qrcode_ qrcode_
jpg creater.py detecter.py

“myQRcode.jpg” selected (9.5 kB)

3.1.3 Program Analysis
The source code of this program is located at:

/home/ubuntu/ros2_ws/src/example/example/qrcode/qrcode_creater.py

file path Get the file path
Global ; The path of the
parameter \_ Ut! output image
q rcod 2 ¢ reater. py \ qreode text Input string prompt
— Function create qrcode

e.QRCode

rrection=qrcode.constants .ERROR_CORRECT_H

@ Creating QR Code Utility Object

Using the qrcode module to create the necessary object and setting various

21



=== Page 22 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

parameters for the QR code.

qrcode.QRCode
version=1,
error_correction=qrcode.constants.ERROR_CORRECT_H,
box_size=5,

_bo

The parameters of the above function are as follows:

The first parameter "version" is an integer ranging from 1 to 40, used to
control the size of the QR code. If you want the program to automatically

determine the size, set this value to None and use the "fit" parameter.

The second parameter "error_correction" controls the error correction

capability of the QR code, with the following options:
1) ERROR_CORRECT_L: can correct approximately 7% or fewer errors.

2) ERROR_CORRECT_M: default value, can correct approximately 15% or

fewer errors.
3) ERROR_CORRECT_H: can correct approximately 30% or fewer errors.

The third parameter "box_size" controls the number of pixels contained in

each small box of the QR code.

The fourth parameter "border" controls the number of boxes included in the
border (distance between the QR code and the image boundary), with a

default value of 4, which is the minimum value specified by relevant standards.
@ Generating QR Code

Using the "add_data" and "make" functions to retrieve and fill data, and then

using the "make_image" function to generate the image.

22



=== Page 23 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

; img = ar make_image(fill_color=(@, @, @), back_color=(255, 255, 2
+i opencv_img = cv2.cvtCoLor(np.asarray(img cv2.COLOR_RGB2BGR

The parameters of the "make_image" function are as follows:

The first parameter "fill_color=(0, 0, 0)" is the fill color of the image, which is

black in this case.

The second parameter "back_color=(255, 255, 255)" is the background color

of the image, which is white in this case.
@ Displaying Image

Converting the color space of the image using the "cvtColor" function, and

then displaying it on the window using the "imshow'" function.

opency img = cv2.cvtColor(np.asarray img), cv2.COLOR_RGB2BGR

cv2.imshow('img', opencv_img
R = cv2.waitKey(1

@ Saving Image

Using the "imwrite" function to store the generated QR code image and

printing relevant information.

e(file_name, opencv_img)

data, file name)

The parameters of the "imwrite" function are as follows:
The first parameter "file_name" is the storage path of the image.

The second parameter "opencv_img" is the image to be stored.

3.2 QR Code Recognition
In the previous section, we created a QR code. In this section, we'll perform

23



=== Page 24 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

content recognition on the QR code.
3.2.1 Recognition Process

Firstly, create an instance object for QR code detection, and pass in the

required network structure and model weight files for detection.
Then, obtain the camera's feedback image and perform detection.

Finally, once the QR code is recognized, it will be framed, and the content of

the QR code will be printed.

The source code for this program is located at:

/home/ubuntu/ros2_ws/src/example/example/qrcode/qrcode_detecter.py

3.2.2 QR Code Recognition Steps

Note: When entering commands, it is necessary to strictly distinguish between
uppercase and lowercase letters, and you can use the "Tab" key to complete

keywords.

1) Start the robot and connect it to the remote control software NoMachine.

2) Click on on the system desktop to open the ROS1 command line
terminal.

3) Enter the command to stop the automatic startup service of the app:

sudo systemctl stop start_app_node.service

stop start_app_node.service

4) Enter the command to start the camera node:

ros2 launch peripherals depth_camera.launch.py

24



=== Page 25 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

5) Open anew ROS2 command line terminal, enter the command to switch to

the program directory, and start the QR code recognition program:

cd ~/ros2_ws/src/example/example/qrcode && python3

qrcode_detecter.py

To close this game, press "Ctrl+C" in the terminal interface. If closing fails,

please try again repeatedly.

3.2.3 Program Outcome

After starting the game, it will recognize the QR code images appearing in the
feedback screen, mark them with a red box, and print out the content of the QR

code.

3 (Unknown),

ubuntu
ubuntu
ubuntu
ubuntu

25



=== Page 26 ===
HIVVE9MCOCT Shenzhen Hiwonder Technology Co,Ltd

3.2.4 Program Analysis

The source code of this program is saved in

/home/ubuntu/ros2_ws/src/example/example/qrcode/qrcode_creater.py

Function main Run the main function
. Image callback
Class QRCodeDetectNode image callback function
»\Function /~ Main function of the QR

_main _code recognition class

3 impo

4 import

> import q

5 import 1

import t

8 import mn as np

9 from | py import Node
10 from sens msg isg import Image

SS QRCodeDetectNode (Nod:
1 _tntt_ (self, me
c L i_ti

daemon=True start()

def image_callback(se
rgb_image iF

@ Main Function

Initialize the QRCodeDetectNode and set the node name as "qrcode_detect".

Wait for the ROS node to close, and if it closes, unregister the current node.

@ QRCodeDetectNode Class

26



=== Page 27 ===
Hiweander Shenzhen Hiwonder Technology Co,Ltd

Initialize the node and define parameters, then start the self.main function.
Parameters:

self.running: Whether the detection is enabled

self.model_ path: Model path

self.image_queue: Image queue

self.image_sub: Subscription to read camera feedback images

self.qcd: Initialization of the QR code detection

Functions:

The camera callback function reads the camera feedback image and places it
in the queue self.image_queue for automatic update and discarding of expired

images.

The main function mainly starts QR code detection. It checks whether

detection is enabled based on the parameter self.running. If it is True, it reads
the image data from the self.image_queue queue, inputs it into the initialized
recognition model self.qcd, and finally prints the recognition content and draws

the recognition box based on the output data.

27



=== Page 28 ===
34 while »€ : ae is
try

HIVVE9MCOCT Shenzhen Hiwonder Technology Co,Ltd

4. Autonomous Line Following

4.1 Recognition Procedure

First, obtain the RGB image from the camera and resize it. Apply Gaussian
blur to the image and convert the color space from RGB to Lab. (For detailed
explanation on Lab color space, please refer to "1 Tutorial Materials\2

Development Basics Course\3 OpenCV Basics Course").

Then, perform color recognition on the objects in the circle using color
thresholding. Apply masking to parts of the image. (Masking is used to globally
or locally mask the processed image using selected images, graphics, or

objects).
Afterward, perform opening and closing operations on the object images.

Finally, outline the largest object with a circle.

Opening operation: First, erode the image and then dilate it. Purpose: Used to
eliminate small objects, smooth the shape boundary, and not change its area.

It can remove small grain noise and break the adhesion between objects.

Erosion: Eliminate the boundary points of the object, causing the boundary to

shrink inward, and can remove objects smaller than the structural element.

28



=== Page 29 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Dilation: Expand the boundary points of the object, merge all background
points in contact with the object into the object, and expand the boundary

outward.

Finally, feedback the recognition results on the feedback screen.

4.2 Autonomous Line Following Operation

Note: The input command should be case sensitive, and keywords can be

complemented using Tab key.

1) Start the robot and connect it to the remote control software NoMachine.

2) Click on on the system desktop to open the command line
terminal.

3) Enter the command to stop the automatic startup service of the app:

sudo systemctl stop start_app_node.service

stop start_app_node.service

4) Enter the following command to enable the camera node.

ros2 launch app line_following_node.launch.py debug:=true

Launch app Line_following_node.launch.py debug:=true

5) Open anew command line terminal, enter the command to navigate to the

program directory, and start the line-following game:

ros2 service call /line_following/enter std_srvs/srv/Trigger {}

6) Then, in the current command line terminal, enter the command to

navigate to the program directory and start the line-following game:

29



=== Page 30 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

ros2 service call /line_following/set_running std_srvs/srv/SetBool "{data:

True}"

7) Click on the position of the line in the image to select the corresponding

color of the track line, and you can start line following by color picking.

Goeavoaeoaue®

(x=347, y=276) ~ R:82 © 109 B:104

8) If you need to close this function, you need to return to the command line

terminal and enter the command to stop it.

ros2 service call /line_following/enter std_srvs/srv/Trigger {}

4.3 Program Analysis

Launch Analysis:

The program file corresponding to this section of the course document is

30



=== Page 31 ===
HIVVE9MCOCT Shenzhen Hiwonder Technology Co,Ltd

located at:

/home/ubuntu/ros2_ws/src/app/launch/scripts/line_following_node.launc

h.py
controller launch Chassis control
—_ Invoked function . depth_camera_launch Depth camera
line_following_node.launch.py lidar_launch Lidar
Invoke line_following_node
— Enabled node line following node _ source code

@ Read the Storage Path

Use ‘get_package_share_directory to obtain the package path.

@ Launch

controller_launch: Start motion control launch.

depth_camera_launch: Start depth camera launch.
lidar_launch: Start lidar launch.
@ None

line_following_node: Start line following node.

31



=== Page 32 ===
Ld =
Hivvent ioer Shenzhen Hiwonder Technology Co,Ltd

Source Code Analysis:

The program file corresponding to this section of the course document is

located at:

/home/ubuntu/ros2_ws/src/app/app/scripts/line_following.py

—Function main Run the main function of this file

_init_ Initialize
LineFollower get_area_max_contour Get the maximum contour
_call__ Class callback function

_init_ Initialize
Indicate the completion
of initialization

| get_node state

main Read the image

Mouse click effect

; : mouse callback callback function
line_following.py Start line-following game
= enter_srv_callback service callback function

2) Exit line-following game
service callback function
' set target color srv_callback .
~ Set line-following target
color service callback function
get_target_color_srv_callback
Get target color service callback function

exit_srv_callback

LineFollowingNode

set_threshold_srv_callback
Set color threshold service callback function

lidar_callback Lidar callback function

image callback Image callback function

Note: it’s necessary to back up the original program file before making any
modification to the program. You’re forbidden to modify the original source code
file to avoid causing robot malfunctions that may be irreparable due to incorrect

parameter modifications!

According to the game’s effect, the process logic of this game is summarized

as shown in the following diagram:

32



=== Page 33 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Capture image (from the camera) Select color wth the color picker

Extract the feature of the line for line following

Robot moves along the line Judge the direction for line following

Subscribe to the topic messages published by the camera node to obtain RGB
images. From the image, identify and select the target line. Determine the
color threshold by picking the color of the line. Based on the line's color
information, extract the features of the line for line following. Calculate the
robot's offset relative to the line's position in the field of view. Control the robot
to move along the line segment, continuously correcting its position to keep the
line at the center of the field of view and use lidar to detect obstacles and avoid

them.

33



=== Page 34 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Color threshold proportion
parameters settings
self.threshold

1.1 Relevant “ “
Paremeters Stop threshold settings
Settings selfstop_threshold
4 Anitialization function
(_ init__(self, Angle movement range settins
“name)) self.scan_angle

1.2 The Defination of Color Picker

set_target_color_srv_callback

1.3 Lidar Obstacle Function
(lidar_callback)

2.1 Image
Pre-processing
Function
image_callback

2.LineFollower
Class 2.2 Logic Judegernent

of the line for
line following
(The Initializaton function
of LineFollower)

Then, the color picker object is defined (used in the gameplay to pick colors),
along with the setting of additional Lidar obstacle avoidance functionality. Next
is the implementation of the LineFollower class, which mainly includes

functions for image preprocessing and logic for line following.

Function:

main
node LineFoLLowingNode('Line_fol

rcLpy.spin(node
node »stroy_node
rcLpy.shutdown

Initiate line following node:

Class:

34



=== Page 35 ===
LineFollower:

covered part is always eliminated)
LineFoLlower:

__init__ (self, color, node
-node node

Init:

__init__|( , color, node
f.node = node
.target_Lab .target_rgb = color
rois = : pies 5
-weight_sum

Set the line-following color and ROI list.

get_area_max_contour:

area_max_contour(contours, threshold=

ReKHR Ao # BE(get the contour of the Largest area)
iparam contours
iparam threshold:
treturn:
ttt
contour_area - contours, ap ( da c: math.fabs(cv2.contourArea(c)), contours
contour_area = tuf filter (lLambde a % threshold, contour_area
u(contour_are 6:
max_c_a = x(contour_area, key=
P max_c_a

Get the contour with the maximum area.

Catt image, result_image, threshold):
centroid_sum i)
h, w = image.shape[:2
min_coLlor = [ ( target_Lab[@] - 5@ * threshold
( .target_Lab[1] x threshold
Lnt ( .target_Lab[2 5@ x threshold
max_coLor [ ( .target_Lab[@] + * threshold
( F.target_Lab x threshold
( f.target_Lab[2] + * threshold
target_color = s .target_Lab color, max_color
roi if -rois:
blob image [i roi[@]*h): roi[1]*xh t i[2]xw):int(roi[3]xw)] # #
(intercept roi)
img_lab = cv2.cvtColor(blob, cv2.COL RGB2LAB #Lab(convert rgb into Lab)
img_blur = cv2.GaussianBLur(img_lLab, P es #§ = 02 (perform Gaussian
filtering to reduce noise)
mask = cv2.inRange(img_blur, target_color([1] yLe(target_color[
(image binarization)
eroded = cv2.erode(mask, cv2.getStructuringELement(cv2.MORPH_RECT, (3,
(corrode)
dilated = cv2.dilate(eroded, cv2.getStructuringElLement(cv2.MORPH_RECT
(dilate)
# cv2.imshow('section: {}:{}'.format(roi[@], roi[1]), cv2.cvtColor(dilated, cv2
. COLOR_GRAY2BGR))
contours = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_L1)[-2
# #24 BE(find the contour)
max_contour_area get_area_ma ontour(contours, 34 LAK HAM BE (get
the contour corresponding to the Largest conto
max_contour_area i None:
rect = cv2.minAreaRect(max_contour_area[@ # #4 FZ (minimum circumscribed
rectangle)

box = np.intp(cv2.boxPoints(rect # (four corners)

box[ 4) = box 95-43 roi[@]x
cv2.drawContours(resuLt_image, [box] . CO, :255, 2 # BHOTtSemoee

Perform color recognition, identify based on the set color, and provide

feedback on the recognized image and angle.

35



=== Page 36 ===
LineFollowingNode:

SS [EREREMAIEEEH ce (Node):
j _init__(self, name):

rclpy.init()

super().__init__ (name)

seLf.name = name
seLF.set_caLLback = False
Lf .is running = Fal

Init:

Lf.name = name
F.set_caLLback =
Lf.is_running =
F.color_picker
.follower = } ,
e .Scan_angle = math.radians(45)
Lf.pid = pid.PID( 1, - )
F.empty - @
F.count = @
.Stop = False

Initialize the required parameters for the program, call the base node, camera
node, and start services such as enter, exit, start, set color, get color, set

threshold, etc.

get_node_state:

get_node_state(self, request, response):
response.success = 2
return response

Set the status of the current node.

Main:

image = self.image_queue.get(bLlock=True, timeout=1)
yt queue.Empty:
tinue

result = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
cv2.imshow("result", result)
if »LFf.debug and no seLf.set_caLlback:

5 t_caLLback

useCallba R tL", seLf.mouse_calLback)
k = cv2.waitKey(1)
ey aoe =a

Read the image and use the mouse to pick colors.

mouse_callback:

36



=== Page 37 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

flags, param

def mouse_callback(self, event, x, y
if event — cv2.EVENT_LBUTTONDOWN:
seLf.get_Logger().info("x:{} y{}".format(x, y
msg = SetPoint.Request()

if self.image_height is not None and self.image_width is not None:
msg.data.x = x seLf.image_width
msg.data.y = y seLf.image_height
seLf.set_target_coLlor_srv_callback(msg, SetPoint.Response

Mouse color picking callback function, obtains the pixel coordinates of the

current mouse position.

enter_srv_callback:

def enter_srv_callback(seLf, request, response):
self.get_Logger() .info('\033[1;32m%s\633[6m' "Line following enter"
try:
if self.image_sub is not None:
self .destroy_subscription(seLf.image_sub
# seLf.im ub.unregister
if self.lidar_sub is not None:
self .destroy scription(self.lidar_sub
# self.Llid .unregister()
except Exception as
self.get_Logger().error(str(e
with self.Lock:
self.stop = False
seLf.is_running = False
self.co picker = None
self.p pid.PID(1.1, 6.0,
seLf.follower = None
self.threshold = @.5
self.empty = 6
self.image_sub = self.create_subscription(Image, '/depth_cam/rgb/image_raw', self.
image_calLback, 1 # - iy e camera)
self.lidar = ption(LaserScan

An kWN

I

/scan', self.Lidar_callback, 1

Enter autonomous line-following service, read data from the camera and lidar,

and initialize actions.

exit_srv_callback:

def exit_srv_callback(self, request, response):
seLf.get_Logger info('\033[1;32m%s\033[em' "Line following exit”
try:
if self.image_sub is not None:
self.image_sub.unregister
if self.Lidar_sub is not None:
self.lidar_sub.unregister
except Exception as e:
self .get_Logger().error(str(e
with seLf.lock:
self.is_running = False
self .color_pick = None
self.pid = pid.PID(@.01, 6.0, 0.0
self.follower = None
self.threshold = @.5
seLf.mecanum_pub.pubLish(Twist(
response.success = True
response.message = "exit"
return response

Exit autonomous line-following service, close various reading nodes, reset PID,

and stop line following.

set_target_color_srv_callback:

37



=== Page 38 ===
Hiwonder Shenzhen Hiwonder Technology Co,Ltd

set_target_coLor_srv_caLlLback(seLf ; Emspente
".get_Logger .info 32m%s \e m'
with F.Lock:
X, y = request.data.x, request.data.y
follower =
4 oie 1:
coLor_picker =

F.color_picker = ColorPicker(request.data
»LF.mecanum <pub pubLlish(Twist
response.success
response.message -
r response

Set line-following color service.

get_target_color_srv_callback:

get target_color_srv_callLback f $s response
.get_Logger <tfifo \933[1;32m%s\¢ On "ge
response.success =
response.message
with Lock:
follower
response.success
rgb se follower. target_ rgb
response.message = ALB Be .format rgb
response

Set up autonomous line-following gameplay.

set_threshold_srv_callback:

set_threshold_srv_caLlLback
-get_Logger info('\@33
with F.lock

threshold = request. data
response. ess =
paspanse- message

response

Set color threshold service.

lidar_callback:

38



=== Page 39 ===
aed callback ( , Lidar_data):
# BK) =- HRAE/E — #180085 (data size= scanning angle/ the increased angle

per scan)

.Lidar_type +
mi index = i math.radians (MAX_SCAN_ANGLE Lidar_data.angle_increment
max_ index nt(math.radians (MAX_SCAN_ANGLE Lidar_data.angle_increment
left_ranges = Lidar_data.ranges[:max # E+wDAH Cle data)
PE ranges = lidar -data ranges [ [:max_index] # A¥#xX (right data)
.Lidar_type =
aintintese: = int math. radians 368 MAX_SCAN_ANGLE 2 Lidar_data.angle_increment

max_index = int(math.radians(180) Lidar_data.angle_increment)
left_ranges = lLidar_data.ranges[ ::-1][min_index:max_index][::-1] # E34ij # (left

right_ranges = Lidar_data.ranges[min_index:max_index : # BXWMMAB (right data)

# #2 Bl Side (Get data according to settings)
angle elf .scan_angle 2

angle_index 1 angle Lidar_data.angle_increment

left_range, right_range = np.array(left_ranges[:angle_index]), np.array(right_ranges

:angle_index]

Left_nonzero = Left_range.nonzero
right_nonzero right_range.nonzero
Left_nonan = ~np.isnan(Left_range[Left_nonzero
right_ nonan = ~np. isnan(right_range[right_nonzero]
# HRA A if 09 FB (Take the nearest distance left and ri
min_dist_left_ = Left_range[lLeft_nonzero Lleft_nonan
min_dist_right_ = right_ range right_ nonzero] [right_nonan]
min_dist_left 4 d min_dist right ; Be
min_dist_left = min_dist left 7
mindist right min_dist_right_.s
min_dist_lLeft « eLlf.stop_threshold or min_dist_right ‘ .Stop_threshold:
stop = Trt

SINS 4

NBFOWOANH

-count += 1
-count
-count = @
-Stop =

ood

i}

Lidar callback function, reorganizes and collates the data read, and

determines whether to stop moving forward.
image_callback:

image_calLback(sel ros_image
rgb_image = np.ndarray(shape=(ros_image.height, ros_image.width, 3), dtype=np.uintés,
ros_image.data # [RG RGB Bi Coriginal RGB image)
.image_height = ros_image.height
image_width = ros_image.width
resuLlt_image = np.copy(rgb_image # ER Hifi (the image used to display the result

with :
# 78 Bi 38 m ; L 25 4F FFigts Bi (color picker and Line recognition
are exclusive. If there olo start picking
-color_picker is not N > # $B E(color picker exists)

target_color, result ~tmage = 4% F.color_picker(rgb_image, result_image
target_coLor :

.color_picker
get_Logge -info("t : SUL EG target_coLlor

f.follower = LineFollower(target_ colar,
Exception e:
.get_Logger().error e

twist = Twist
twist.Linear.x =
F.follower is not Ne

result_image, deflection_angle .follower(rgb_image, result_image,
F.threshold
deflection _angle not N 1 sé .iS_running d t .Stop:
-pid. update deeTRetton: “angle)
twist. anguLlar.z = common.set_range(- F.pid.output,
-mecanum_pub.publish(twist
.Stop:
-mecanum_pub.pubLlish(Twist

seLf.pid.clear
Exception as e:
get_Logger().error
-debug:
- image_queue ue

Camera callback function, invokes the color picker based on the read data,

39



=== Page 40 ===
b— IVE) mM Oo © Shenzhen Hiwonder Technology Co,Ltd

and moves the robot according to the recognized line using PID control.

40


