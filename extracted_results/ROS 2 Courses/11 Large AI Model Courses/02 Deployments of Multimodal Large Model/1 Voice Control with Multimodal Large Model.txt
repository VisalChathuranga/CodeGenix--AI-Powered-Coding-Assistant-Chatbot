
=== Page 1 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Voice Control with Multimodal Large
Model

1 Brief Overview of Operation

Once the program starts running, the Six-Microphone Circular Array will
announce “I’m Ready,” hereafter called the voice device. To activate the voice
device, speak the designated wake words: “Hello Hiwonder.” Upon successful
activation, the voice device will respond with “I’m Here.” Following activation,
the robot can be controlled through voice commands. Example commands
include: “Move forward, backward, turn left, turn right, sideways, and then
drift.” The voice device will process the instruction, announce the

corresponding response, and execute the specified action.

Getting Started

2.1 Version Confirmation

Before starting this feature, verify that the correct microphone

configuration is set in the system.

1) Log in to the machine remotely via NoMachine. Then click the desktop

icon Tool to access the configuration interface.

2) First, verify the system language setting.

3) For the Six-Microphone Circular Array, select xf as the microphone

1



=== Page 2 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

type as shown in the figure.

AP Name HW-24347055

Version V1.1.1 2025-05-20

whens EE
ROS2 Humble

4) After making the appropriate selection, click Save.

5) A “Save Success” message will confirm that the configuration has

been stored in the system environment.

Save Success

6) Then, click Quit to close the interface.

2



=== Page 3 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

2.2 Configuring the Large Model API-KEY

Open a new command-line terminal and enter the following command to

access the configuration file.

vim /home/ubuntu/ros2_ws/src/large_models/large_models/large_models/config.py

Refer to the tutorial under “Al Large Language Model Course / 1 Large
Language Model Basic Courses/1.1 Large Language Model Courses/1.1.2
Large Language Model Deployment” to obtain the API keys. For the vision
language model, acquire the API key from the OpenRouter official website and
assign it to the vllm_api_key variable. For the large language model, obtain
the API key from the OpenAI official website and assign it to the
llm_api_key variable. Ensure that the keys are inserted in the designated

positions, as indicated by the red boxes in the reference image.

25, vllm_apt_key =

26 vllm_base url =
27 villm_model =

9) LLm api key =

© Llm_base_url =

1 Llm_model =

2 openai_vllm_model =
3 openai_tts_model =

4 openai_asr_model =
35 openai_voice_model =

3 Enabling and Disabling the Feature

@ 1. Command input is case-sensitive and space-sensitive.




=== Page 4 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

2. The robot must be connected to the Internet, either in STA (LAN)

mode or AP (direct connection) mode via Ethernet.

1) Open the command line terminal from the left side of the system

terrace, Bl In the terminal window, enter the following command
and press Enter to stop the auto-start service.

sudo systemctl stop start_app_ node.service

stop start app node.service

2) Enter the following command and press Enter to launch the voice

control feature.

ros2 launch large models examples 1lm_control_move.launch.py

ros2 Launch Large_models_examples Llm_control_move.launch.py

3) When the terminal displays output shown in the figure and the Circular
Microphone Array announces "I’m ready", the device has completed

initialization. Then, you can say the wake words: "Hello Hiwonder".

tts_node-11] [INFO] [1745651715.944763195] [tts_node]: [Playback Thread] Playback stream stopped and closed.
tts_node-11] [INFO] [1745651715.946849316] [tts_node]: [TTS] Playback task complete.

vocal_detect-9] [INFO] [1745651715.953090211] [vocal_detect]:

4) When the terminal displays the corresponding output shown in the
figure and the device responds with "I’m here", it indicates successful

activation. The system will begin recording the user's voice command.

[vocal_detect-9] [INFO] [1745651723.831605276] [vocal_detect]:

[vocal_detect-9] [INFO] [1745651724.849539367] [vocal_detect]:

5) When the terminal displays the next output as the reference image, it

shows the recognized speech transcribed by the device.




=== Page 5 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

6) Upon receiving user input shown in the figure, the terminal will display
output indicating that the cloud-based large language model has been
successfully invoked. The model will interpret the command, generate a
language response, and execute a corresponding action based on the

meaning of the command.

@ ire response is automatically generated by the model. While the
semantic content is accurate, the wording and structure may vary due to

randomness in language generation.

7) When the terminal shows the output shown in the figure indicating the

end of one interaction cycle, the system is ready for the next round. To initiate
another interaction, repeat step 4 by speaking the wake words again.

[| tts_node-11] [INFO] [1745651742.920891269] [tts_node]: Time to first byte: 2.36 seconds
[tts_node-11] [INFO] [1745651744.190393534] [tts_node]: [Playback Thread] Playback stream stopped and closed.

[tts_node-11] [INFO] [1745651744.192503709] [tts_node]: [TTS] Playback task complete.

[ vocal_detect-9] [INFO] [1745651744.198584460] [vocal_detect]:

8) To exit the feature, press Ctrl+C in the terminal. If the feature does not
shut down immediately, press Ctrl+C multiple times. If it still fails to exit, open
a new terminal window and run the following command to terminate all active

ROS processes and related programs.

~/.stop_ros.sh

4 Project Outcome

Once the feature is activated, feel free to give commands in your own

words. For instance, "Move forward, backward, turn left, turn right,



=== Page 6 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

sideways, and then drift." The robot will move forward and backward, shift

left and right, and then perform a turning drift motion.

5 Program Brief Analysis

5.1 Launch File Analysis

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_examp

les/IIm_control_move.launch.py

@ Import Libraries

rt os
ament_index_python. packages get_package_share_directory

launch_ros.actions t Node
) Launch.substitutions tr t LaunchConfigurattion
) Launch rt LaunchDescription, LaunchService
1 launch. Launch_description_sources rt PythonLaunchDescripttonSource
Launch. actions rt IncludeLaunchDescripttion, DeclareLaunchArgument, OpaqueFunction

@ os: used for handling file paths and operating system-related

functions.

@ ament index python.packages.get package share direc

tory: retrieves the share directory path of ROS 2 package.

@) launch ros.actions.Node: used to define ROS 2 nodes.

@ launch.substitutions.LaunchConfiguration: retrieves

parameter values defined in the Launch file.

© LaunchDescription, LaunchService: used to define and start

the Launch file.

© launch description sources

6



=== Page 7 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

PythonLaunchDescriptionSource: enables the inclusion of other

Launch files.

@ launch.actions.IncludeLaunchDescription,
DeclareLaunchArgument, OpaqueFunction: used to define actions and

arguments within the Launch file.

@ Definition of the launch_setup Function

(context):
mode = LaunchConfiguration( , default=1)
mode_arg = DeclareLaunchArgument( , default_value=mode)

controller_package_path = get_package_share_directory(
Llarge_models_package_path = get_package_ share_directory(

controller_Launch = IncludeLaunchDescription(
PythonLaunchDescriptionSource(
os.path. join(controller_package_path,
)

Large_models_launch = IncludeLaunchDescription(
PythonLaunchDescriptionSource(
os.path. join(large models_package_ path,
Launch_arguments={ : mode}.items(),

)

Llm_control_move_node = Node(
package=
executable=

output=
)

rn [mode_arg,
controller_launch,
large_models_launch,
Llm_control_move_node,

]

(@ This function is used to configure and initialize Launch actions.

@ mode = LaunchConfiguration('mode', default=1) defines a

Launch argument named mode with a default value of 1.

@ mode arg = DeclareLaunchArgument ('mode',

default value=mode) declares the mode argument and includes it in the

Launch description.

@ Controller path and large models package path

represent the shared directory paths for the controller package responsible for

robot movement and the large models package.



=== Page 8 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

©) controller launch includes the Launch file

controller.launch.py from the controller package using

IncludeLaunchDescription.

© large models launch includes the Launch file

start.launch.py from the large _models package using

IncludeLaunchDescription and passes the mode argument to it.
@ The function returns a list of all defined Launch actions.

@ Definition of the generate _launch_description Function

():

eturn LaunchDescription( [

OpaqueFunction(function = Launch setup)

@_ This function is responsible for generating the complete Launch

description.

@ The launch_setup function is incorporated using

OpaqueFunction.

@ Main Program Entry

if name =a :
ld = generate_launch_description()

ls = LaunchService()
Lls.include_lLaunch_description(1ld)
Lls.run()

@ 1d= generate launch description() generates the Launch

description object.

@ 1s = LaunchService() creates the Launch service object.

@ 1s.include launch description(ld) adds the Launch

description to the service.



=== Page 9 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

@ 1s.run() starts the service and execute all Launch actions.

5.2 Python File Analysis

File Path:

ros2_ws/src/large_models_examples/large_models_examples/IIm_c

ontrol_move.py

@ Prompt Template Definition

@ Variable Initialization

(Node):
__ (self, name):
rclpy.init()
().__init__(name)

self.action = []
self.1llm_result =
self.running =
self.interrupt =
self.action_finish =
self.play_audio_ finish =

@ self.action: stores the list of actions parsed from LLM responses.

@ self.lim result: stores the result received from the LLM.

@ self.running: a flag indicating whether the main loop is actively

running.

@ self.interrupt: a flag indicating whether the current function has



=== Page 10 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

been interrupted or stopped.

© Self.action finish: a flag indicating whether the current action

has been completed.

© self.play audio finish: a flag indicating whether the audio

playback has finished.

@ Publisher Creation

.create_publisher(String,

Creates a publisher that sends String messages to the topic
/tts node/tts_text. This topic is used to send text-to-speech (TTS)

content for voice feedback.

@ Subscriber Creation

self.create_subscription(String, ,» self.llm_result_callback, 1)
self.create_subscripttion(Bool, , self.wakeup_callback, 1, callback_group=timer_cb_group)

self.create_subscription(Bool, , self.play_audio_finish_callback, 1, callback_group=timer_cb_group)
self.set_model_client = self.create_client(SetModel, )
> set model clie j service()

@ Timer Creation

self.timer = self.create_timer( » self.init_process, callback_group=timer_cb_group)

@ LLM Model Configuration

msg = SetModel.Request()

msg.model = Llm_model

msg.model_type =

msg.api_key = api_key

msg.base_url = base_url
self.send_request(self.set_model_client, msq)

@ play audio finish_callback Method:

(self, msg):
msg = SetInt32.Request()

msq.data =
self.send_request(self.set_mode_ client, msg)
self.play_audio_ finish = msg.data

Callback function triggered after voice playback finishes, and re-enables

10



=== Page 11 ===
voice wakeup functionality.

@ process Method

def process(self):
while self.running:
if self.llm_result:

msg = String()

if in self.1llm_result: # If there is a corresponding action returned, extract and process it
result = eval(self.llm_result[self.1llm_result. find( ):self.1llm_result. find( ) + 1))
self .get_logger().info(str(result))
action_list = []
if in result:

action_list = result[

self.tts_text_pub.publish(msg)
for i in action_list:
Twist()
sg.linear.x = float(i[o])
msg.linear.y = float(i[1])
msg.angular.z = float(i[2])

ecanum_pub.publish(msg)
-sleep(i[3])
self.interrupt:
self.interrupt = False
self .mecanum_pub.publish(Twist())
break
else: # If there is no corresponding action, just
response = self.1llm_result
msg.data = response
self.tts_text_pub.publish(msg)
self.action_finish = True
self.llm_result =
else:
time.sleep( )
if self.play_audio_finish and self.action_finish:
self.play_audio_finish = False

# €
rclpy.shutdown()

The main processing loop handles instructions from the LLM, parses them,
and performs corresponding robot actions. It also supports generating and

broadcasting voice feedback.

@ main Function

def main():
node = LLMControlMove(
executor = MultiThreadedExecutor()

executor.add_ node(node)
executor.spin()
node.destroy_node()

@_ The function initializes a ROS 2 node.
@) It starts a multi-threaded executor to handle callbacks.

@ Itcleans up and destroys the node upon program exit to release

resources

11


