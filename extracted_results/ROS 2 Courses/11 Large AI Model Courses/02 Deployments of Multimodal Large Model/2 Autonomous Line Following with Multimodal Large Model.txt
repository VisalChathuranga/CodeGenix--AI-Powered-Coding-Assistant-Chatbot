
=== Page 1 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Autonomous Line Following with
Multimodal Large Model

1 Brief Overview of Operation

Once the program starts running, the Six-Microphone Circular Array will
announce “I’m Ready,” hereafter called the voice device. To activate the voice
device, speak the designated wake words: “Hello Hiwonder.” Upon
successful activation, the voice device will respond with “I’m Here.” Once
activated, voice commands such as “Follow the black line and stop when
you encounter an obstacle” can be issued. The terminal will display the
recognized command, and the voice device will respond with a generated reply
after processing. The robot will then follow the black line detected by the

camera and stop automatically when an obstacle is detected ahead.

2 Getting Started

2.1 Version Confirmation

Before starting this feature, verify that the correct microphone

configuration is set in the system.

1) Log in to the machine remotely via NoMachine. Then click the desktop

icon to access the configuration interface.

2) First, verify the system language setting.

3) For the Six-Microphone Circular Array, select xf as the microphone

type as shown in the figure.



=== Page 2 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

AP Name HW-24347055

Version V1.1.1 2025-05-20

wen EE
ROS2 Humble

4) After making the appropriate selection, click Save.

5) A “Save Success” message will confirm that the configuration has

been stored in the system environment.

Save Success

6) Then, click Quit to close the interface.



=== Page 3 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

2.2 Configuring the Large Model API-KEY

Open a new command-line terminal and enter the following command to

access the configuration file.

vim /home/ubuntu/ros2_ws/src/large_models/large_models/large_models/config.py

Refer to the tutorial under “Al Large Language Model Course / 1 Large
Language Model Basic Courses/1.1 Large Language Model Courses/1.1.2
Large Language Model Deployment” to obtain the API keys. For the vision
language model, acquire the API key from the OpenRouter official website and
assign it to the vllm_api_key variable. For the large language model, obtain
the API key from the OpenAI official website and assign it to the
llm_api_key variable. Ensure that the keys are inserted in the designated

positions, as indicated by the red boxes in the reference image.

25, vllm_apt_key =

26 vllm_base url =
27 villm_model =

9) LLm api key =

© Llm_base_url =

1 Llm_model =

2 openai_vllm_model =
3 openai_tts_model =

4 openai_asr_model =
35 openai_voice_model =

3 Enabling and Disabling the Feature

@ 1. Command input is case-sensitive and space-sensitive.

2. The robot must be connected to the Internet, either in STA (LAN)

mode or AP (direct connection) mode via Ethernet.

3



=== Page 4 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

1) Open the command line terminal from the left side of the system

terface Ail In the terminal window, enter the following command

and press Enter to stop the auto-start service
sudo systemctl stop start_app_ node.service
stop start app node.service

2) Enter the following command and press Enter to launch the

autonomous line following feature.

ros2 launch large models examples 1lm_visual_patrol.launch.py

launch Large_models_examples Llm_visual_patrolL. Launch. py

3) When the terminal displays output shown in the figure and the Circular
Microphone Array announces "I’m ready", the device has completed

initialization. Then, you can say the wake words: "Hello Hiwonder".

[tts_node-12] [INFO] [1741420835.433849545] [tts_node]:
[vocal_detect-10] [INFO] [1741420836.113594389] [vocal_detect]:
[agent_process-11] [INFO] [1741420836.723263596] [agent_process]:
[agent_process-11] [INFO] [1741420836.950927860] [agent_process]:

[agent_process-11] [INFO] [1741420837.117932434] [agent_process]:
(waste_classification-9] [INFO] [1741420837.137882793] [waste_classification]:
[llm_waste_classification-13] [INFO] [1741420839.230102414] [1llm_waste_classification]:

4) When the terminal displays the corresponding output shown in the
figure and the device responds with "I’m here", it indicates successful

activation. The system will begin recording the user's voice command.

1742354788 .479444235

1742354788 .487067532 vocal detect]:

5) For example, saying “Follow the black line and stop when you
encounter an obstacle’ will trigger the voice device to process the command.
Upon successful recognition by the speech recognition service of cloud-based
large speech model, the parsed command will be displayed under the

publish asr_ result output in the terminal.



=== Page 5 ===
fs Shenzhen Hiwonder Technology Co,Ltd

L_detect]:

Hiweande

NFO] [1745653462. 402367607] [vocal_detect]: Follow the black Line and stop wher

6) Upon receiving user input shown in the figure, the terminal will display

output indicating that the cloud-based large language model has been
successfully invoked. The model will interpret the command, generate a
language response, and execute a corresponding action based on the

meaning of the command.

@ The response is automatically generated by the model. While the
semantic content is accurate, the wording and structure may vary due to

randomness in language generation.

[agent_process-14] [INFO] [1745653462.403364682] [agent_process]:
[agent_process-14] [INFO] [1745653464.294357566] [agent_process]:

[agent_process-14] "action": ["Line_following('black')"],

[agent_process-14] "response": "On it, Line dancer!"

[agent_process-14] }

7) When the terminal shows the output shown in the figure indicating the
end of one interaction cycle, the system is ready for the next round. To initiate

another interaction, repeat step 4 by speaking the wake words again.



=== Page 6 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

[tts_node-15] [INFO] [1745653468.118236235] [tts_node]: [Playback Thread] Playback stream stopped and closed.
tts_node-15] [INFO] [1745653468.119680518] [tts_node]: [TTS] Playback task complete.

[vocal_detect-13] [INFO] [1745653468.130963131] [vocal_detect]:

8) To exit the feature, press Ctrl+C in the terminal. If the feature does not

exit immediately, press Ctrl+C multiple times.

4 Project Outcome

Once the feature is activated, feel free to give commands in your own
words. For instance, “Follow the black line and stop when you encounter
an obstacle.” The robot uses its camera to detect and follow the black line,
and it will stop when an obstacle is detected in its path. The system is

pre-configured to recognize four line colors: red, blue, green, and black.
5 Program Brief Analysis

5.1 Launch File Analysis

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_exam

ples/IIm_visual_patrol.launch.py

@ Import Libraries

re

time

rclpy

threading
rclpy.node Node
std_msgs.msg String, Bool
std_srvs.srv Trigger, SetBool, Empty

speech speech

interfaces.srv ’ SetString as SetColor
Large_models.config *

large _ models msgs.srv ij “t SetModel, SetString, SetInt32

rclpy.executors MultiThreadedExecutor
rclpy.callback groups i rt ReentrantCallbackGroup

@ os: used for handling file paths and operating system-related



=== Page 7 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd

functions.

@) ament index python.packages.get package share direc

tory: retrieves the share directory path of ROS 2 package.

(6) launch_ros.actions.Node: used to define ROS 2 nodes.

@ launch.substitutions.LaunchConfiguration: retrieves

parameter values defined in the Launch file.

©) LaunchDescription, LaunchService: used to define and start

the Launch file.

© launch description sources

PythonLaunchDescriptionSource: enables the inclusion of other

Launch files.

@ launch.actions.IncludeLaunchDescription,

DeclareLaunchArgument, OpaqueFunction: used to define actions and

arguments within the Launch file.

@ Definition of the launch_setup Function



=== Page 8 ===
(context):
mode = LaunchConfiguration( le', default=1)
mode_arg = DeclareLaunchArgument( e', default_value=mode)

app_package_ path = get_package share_directory( »)
large_models_package_ path = get_package_ share_directory(

Line_following_node_launch = IncludeLaunchDescription(
PythonLaunchDescriptionSource(
os.path. join(app_package_path,
Launch_arguments={

}.items(),

large_models_lLaunch = IncludeLaunchDescription(
PythonLaunchDescriptionSource(
os.path. join(large_models_package path,
Launch_arguments={ le': mode}.items(),

)

Llm_visual_patrol_node = Node(
package=' | de
executable=
output=

)

return [mode arg,
line_following_node_launch,
Large_models_launch,
Llm visual patrol_node,

]

(@ This function is used to configure and initialize Launch actions.

@ mode = LaunchConfiguration('mode', default=1) defines

a Launch argument named mode with a default value of 1.

@ mode _ arg = DeclareLaunchArgument ('mode',

default value=mode) declares the mode argument and includes it in the

Launch description.

@ large models package path: retrieves the shared directory path

of the large _ models package.

©) waste classification launch: includes the file

waste classification launch using IncludeLaunchDescription.

© large models launch: includes the Launch file

start.launch.py fromthe large models package using



=== Page 9 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

IncludeLaunchDescription and passes the mode argument to it.

@ 11m vision pratrol: defines a ROS 2 node from the

large models package, executes the executable files from the

llm_vision_patrol, and prints the node's output to the screen.
The function returns a list of all defined Launch actions.

@ Definition of the generate launch description Function

():

rn LaunchDescription([

OpaqueFunction(function = Launch setup)

@_ This function is responsible for generating the complete Launch

description.

@ The launch setup function is incorporated using

OpaqueFunction.

@ Main Program Entry

if name =a :
ld = generate_launch_description()

ls = LaunchService()
Lls.include_lLaunch_description(1ld)
Lls.run()

@ 1d= generate launch description() generates the Launch

description object.

@ 1s = LaunchService() creates the Launch service object.

@ 1s.include launch description (1d) adds the Launch

description to the service.



=== Page 10 ===
@ 1s.run()_ starts the service and execute all Launch actions.

5.2 Python File Analysis

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_exam

ples/IIm_visual_patrol.py

@ Import Libraries

re
rt time

rclpy

threading
speech speech
rclpy.node i t Node
std_msgs.msg port String, Bool
std_srvs.srv ’ tf Trigger, SetBool, Empty

interfaces.srv t SetString as SetColor
Large_models.config import *
lLarge_models_msgs.srv im ct SetModel, SetString, SetInt32

rclpy.executors import MultiThreadedExecutor
rclpy.callback_groups rt ReentrantCallbackGroup

5
6 i
7
8
9
io]
1
2
3
4
5
6
7
8
9

@ Prompt Template Definition

You are a smart robot that generates corresponding JSON commands based on user input.

**Requirements

- For every user input, search for matching commands in the action function library and output the corresponding JSON instruction.
For each action sequence, craft a witty and creative response (10 to 3@ characters) to make interactions delightful

- Directly return the JSON result — do not include any explanations or extra text.

- There are four target colors: red, green, blue, and black.
Format:

**Special Notes
The “action” f should contain a list of function names as strings, ordered by execution. If no matching action is found, output an empty list: [].
The “response” field should provide a concise and charming reply, staying within the word and tone guidelines.

**action Function Library
Follow a line of a given color: line_following( ‘black’ )

**Example
Input: Follow the black line
Output:
v{
“action”: [“line_following(‘black’)"],
“response”: “Roger that!”

@ Variable Initialization

self.actio

self.stop >
self.llm result =

@ self.action: stores the list of actions parsed from LLM responses.

10



=== Page 11 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd

@ self.lim result: stores the result received from the LLM.

@ self.running: a flag indicating whether the main loop is actively

running.

@ Publisher Creation

self.tts_text_pub = self.create_publisher(String,

Creates a publisher that sends String messages to the topic
/tts node/tts_text. This topic is used to send text-to-speech (TTS)

content for voice feedback.

@ Subscriber Creation

@ Necessary Services Creation

set_model_client = self.create_client(SetModel,
set_model_client.wait_for_service()
set_prompt_client = self.create_client(SetString,
set_prompt_client.wait_for_service()

enter_client = self.create_client(Trigger,
enter_client.wait_for_service()

start_client = self.create_client(SetBool,
start_client.wait_for_service()

set_target_client = self.create _client(SetColor,
set_target_client.wait_for_service()

@ LLM Model Configuration

msg = SetModel.Request()

msg.model = Llm_model

msg.model_type =

msg.api_key = api_key

msg.base_url = base _url
self.send_request(self.set_model_client, msg)

@ Enter

self.send request(self.set_prompt_client, msg)

@ Play Startup Audio

speech.play audio(start_audio path)

11



=== Page 12 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

@ Process LLM Commands to Create Speech Feedback Messages

@ Check if the Command Contains Actions

1 self.LLm_result:

result = (self. llm_result[self.1llm_result. find( ):self.1Lllm result. find( )+1))

@ Parse the Command

(self. 11lm_result[self.1lm_result. find( ):self.1lLm_result. find( )+1]

@ Extract the Recognized Results

in result:
text = result[
pattern =

@ Set Target Color Request

color = match.group(1)
self .get_lLogger().info( (color))

color_msg = SetColor .Request()
color_msg.data = color
self.send request(self.set_target_ client, color msg)

Create a SetStringList.Request message to specify the target for

waste classification. Use the send_request method to send the request to

the waste classification/set target service, setting the waste

Classification target.

@ Initiate and Send Request to Start Line Following

start_msg = SetBool.Request()

start_msg.data =
self.send_request(self.start_client, start_msg)

Create a SetBool.Request message to enable the waste classification
transport feature. Use the send_request method to send a request to the

waste classification/enable transport service, starting the waste

classification transport.

@ main Function

12



=== Page 13 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd
7 QO

7 node = LLMCoLlorTrack( )
7 executor = MultiThreadedExecutor()
executor.add node(node)

executor .spin()
node.destroy_node()

@_ The function initializes a ROS 2 node.
@) It starts a multi-threaded executor to handle callbacks.

@ Itcleans up and destroys the node upon program exit to release

resources.

13


