
=== Page 1 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Real-Time Detection in Embodied Al
Applications

The large model used in this lesson operates online, requiring a stable

network connection for the main controller in use.

1 Brief Overview of Operation

Once the program starts running, the Six-Microphone Circular Array will
announce “I’m Ready,” hereafter called the voice device. To activate the voice
device, speak the designated wake words: “Hello Hiwonder.” Upon
successful activation, the voice device will respond with “I’m Here.” After
activation, the robot can be controlled via voice commands. For example,
saying “Tell me what you saw’ will prompt the system to print the recognized
speech on the terminal. The voice device will then announce the generated
response after processing, and the robot will autonomously interpret the

camera feed and describe the visual content.

2 Getting Started

2.1 Version Confirmation

Before starting this feature, verify that the correct microphone

configuration is set in the system.

1) Log in to the machine remotely via NoMachine. Then click the desktop

icon io to access the configuration interface.

2) First, verify the system language setting.



=== Page 2 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

3) For the Six-Microphone Circular Array, select xf as the microphone

type as shown in the figure.

AP Name HW-24347055

Version V1.1.1 2025-05-20

wen EE
ROS2 Humble

4) After making the appropriate selection, click Save.

5) A “Save Success” message will confirm that the configuration has

been stored in the system environment.



=== Page 3 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Save Success

6) Then, click Quit to close the interface.

2.2 Configuring the Large Model API-KEY

Open a new command-line terminal and enter the following command to

access the configuration file.

vim /home/ubuntu/ros2_ws/src/large_models/large_models/large_models/config.py

Refer to the tutorial under “Al Large Language Model Course / 1 Large
Language Model Basic Courses/1.1 Large Language Model Courses/1.1.2
Large Language Model Deployment” to obtain the API keys. For the vision
language model, acquire the API key from the OpenRouter official website and
assign it to the vllm_api_key variable. For the large language model, obtain
the API key from the OpenAI official website and assign it to the
llm_api_key variable. Ensure that the keys are inserted in the designated

positions, as indicated by the red boxes in the reference image.

vllm_apt_key =
26 vilm_base_url =
7 vilm_model =

9° 1Lm apt key =

© Llm_base_url =

1 Llm_model =
2 openai_vllm_model =
3 openai_tts_model =

4 openai_asr_model =

> Openai_voice_model =




=== Page 4 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd
3 Enabling and Disabling the Feature

1) Open the command line terminal from the left side of the system

terface al In the terminal window, enter the following command

and press Enter to stop the auto-start service
sudo systemctl stop start_app_ node.service

stop start app node.service

2) Enter the following command and press Enter to launch the real-time

detection feature.

ros2 launch large models examples vllm_with_camera.launch.py

launch Large _ models examples vllm_with_camera.launch.py

3) When the terminal displays output shown in the figure and the Circular
Microphone Array announces "I’m Ready", the device has completed

initialization. Then, you can say the wake words: "Hello Hiwonder".

[tts_node-9] [INFO] [1741432989.434131717] [tts_node]:
[agent_process-8] [INFO] [1741432989.966613812] [agent_process]:
[vocal_detect-7] [INFO] [1741432990.060075281] [vocal_detect]:

[agent_process-8] [INFO] [1741432990.161832320] [agent_process]:
(vllm_with_camera-10] [INFO] [1741432991.718093717] [vllm_with_camera]:

4) When the terminal displays the corresponding output shown in the
figure and the device responds with "I’m Here", it indicates successful

activation. The system will begin recording the user's voice command.

[vocal_detect-7] [INFO] [1741419606.799872983] [vocal_detect]:

[vocal_detect-7] [INFO] [1741419606.805699617] [vocal_detect]:

5) When the terminal displays the next output as the reference image, it

shows the recognized speech transcribed by the device.

The system will begin recording the user’s voice command, and you can
say the command “Tell me what you saw” and wait for the large model to

process the input.



=== Page 5 ===
M4 iweander Shenzhen Hiwonder Technology Co,Ltd

6) Upon successful recognition by the speech recognition service of

cloud-based large speech model, the parsed command will be displayed under

the publish_asr_result output in the terminal.

7) Upon receiving user input shown in the figure, the terminal will display
output indicating that the cloud-based large language model has been
successfully invoked. The model will interpret the command and generate a

language response.

@ The response is automatically generated by the model. While the
semantic content is accurate, the wording and structure may vary due to

randomness in language generation.

8) When the terminal shows the output shown in the figure indicating the

end of one interaction cycle, the system is ready for the next round. To initiate

5



=== Page 6 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

another interaction, repeat step 4 by speaking the wake words again.

[tts_node-9] [INFO] [1741433173.244323492] [tts_node]: Speech synthesizer is opened.
[tts_node-9] [INFO] [1741433207.904857317] [tts_node]: Speech synthesizer is completed.

[tts_node-9] [INFO] [1741433207.911633321] [tts_node]: Speech synthesizer is closed.
vocal_detect-7] [INFO] [1741433207.923092407] [vocal_detect]:

9) To exit the feature, press Ctrl+C in the terminal. If the feature does not

exit immediately, press Ctrl+C multiple times.

4 Project Outcome

Once the feature is active, speaking a command such as “Tell me what
you saw” prompts the robot to autonomously analyze its visual environment

and describe the current scene based on its observations.

5 Program Brief Analysis

5.1 Launch File Analysis

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_exam

ples/vilm_with_camera.launch.py

@ Import Libraries

t os
| ament_index_python. packages rt get_package_share_directory

) Launch_ros.actions it t Node
1 Launch.substitutions im LaunchConfigurattion
) Launch tf t LaunchDescription, LaunchService
Launch. Launch_descriptton_sources t PythonLaunchDescriptionSource
m Launch.acttions t IncludeLaunchDescription, DeclareLaunchArgument, OpaqueFuncttion

@ os: used for handling file paths and operating system-related

functions.

@ ament index python.packages.get package share direc

6



=== Page 7 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

tory: retrieves the share directory path of ROS 2 package.

(6) launch_ros.actions.Node: used to define ROS 2 nodes.

@ launch.substitutions.LaunchConfiguration: retrieves

parameter values defined in the Launch file.

© LaunchDescription, LaunchService: used to define and start

the Launch file.

© launch description sources

PythonLaunchDescriptionSource: enables the inclusion of other

Launch files.

@ launch.actions.IncludeLaunchDescription,

DeclareLaunchArgument, OpaqueFunction: used to define actions and

arguments within the Launch file.

@ Definition of the launch _setup Function

(context):
mode = LaunchConfiguration( , default=1)
mode_arg = DeclareLaunchArgument( , default_value=mode)

camera_topic = LaunchConfiguration( , default= )
camera_topic_arg = DeclareLaunchArgument( , default_value=camera_topic)

controller_package_path = get_package_share_directory( )
peripherals_package path = get_package_share_directory( )
Large_models_package_path = get_package_share_directory( )

controller_launch = IncludeLaunchDescription(
PythonLaunchDescriptionSource(
os.path. join(controller_package_path,
)

depth_camera_launch = IncludeLaunchDescription(
PythonLaunchDescripttonSource(
os.path.join(peripherals_ package path,
)

large_models_launch = IncludeLaunchDescripttion(
PythonLaunchDescriptionSource(
os.path. join(large_models_package_path, »),
Launch_arguments={ : mode, : camera_topic}.items(),

)

vllm_with_camera_node = Node(
package=
executable=
output= 5
parameters=[{ : camera_topic}],

)

return [mode_arg,
camera_topic_arg,
controller_launch,
depth_camera_launch,
large_models_launch,
vllm_with_camera_node,

]




=== Page 8 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

(@ This function is used to configure and initialize Launch actions.

@ mode = LaunchConfiguration('mode', default=1) defines

a Launch argument named mode with a default value of 1.

(@)) mode _ arg = DeclareLaunchArgument ('mode',

default value=mode) declares the mode argument and includes it in the

Launch description.

@ depth camera_launch includes the Launch file

depth _camera.launch.py fromthe large models package using

IncludeLaunchDescription and passes the mode argument to it.

© sdk launch includes the Launch file jetarm_ sdk.launch.py

from the large_models package using IncludeLaunchDescription and

passes the mode argument to it.

© large models launch: includes the Launch file

start.launch.py from the large models package using

IncludeLaunchDescription and passes the mode argument to it.

®M vi lm_with_ camera defines a ROS 2 node from the

large models package, executes the executable files from the

vilm_with_camera, and prints the node's output to the screen.

The function returns a list of all defined launch actions.

@ Definition of the generate launch description Function

' ' '
return LaunchDescription([

OpaqueFunction(function = Launch_setup)

])

@_ This function is responsible for generating the complete launch

description.



=== Page 9 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

@ The launch setup function is incorporated using

OpaqueFunction.
@ Main Program Entry

if name
ld a

ls = LaunchService()
Lls.include_lLaunch_description(1ld)
Lls.run()

@ 1d = generate launch description() generates the launch

description object.

@ 1s = LaunchService() creates the launch service object.

@ 1s.include launch description (1d) adds the launch

description to the service.

@ 1s.run() starts the service and execute all launch actions.

5.2 Python File Analysis

The source code for this program is located at:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_exam

ples/vilm_with_camera.py

@ Import the necessary libraries



=== Page 10 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

t os
cv2
t json
ort queue
t rclpy
t threading
t numpy as np

1 rclpy.node import Node
1 cv_bridge i -t CvBridge
sensor_msgs.msg i t Image

om std _msgs.msg ir rt String, Bool
std_srvs.srv import Trigger, SetBool, Empty
) rclpy.executors i t MultiThreadedExecutor
rclpy.callback_groups import ReentrantCallbackGroup

1 speech rt speech
large_models.config import *
large_models_msgs.srv import SetModel, SetString, SetInt32
1 servo_controller.bus_ servo_control import set_servo_position
) servo_controller_msgs.msg 1 rt ServosPosition, ServoPosition

(© cv2: Utilized for image processing and display using OpenCV.
@ time: manages execution delays and time-related operations.
@ queue: handles image queues between threads.

@ vxrclpy: provides tools for creating and communicating between ROS

2 nodes.

© threading: enables multithreading for concurrent task processing.
© config: contains configuration file.
@ numpy (np): supports matrix and vector operations.

std_srvs.srv: contains standard ROS service types, used to

define standard service.

@ std _msgs.msg: contains standard ROS message types.

sensor msgs.msg. Image: used for receiving image messages

from the camera.

10



=== Page 11 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

11. servo controller msgs.msg.ServosPosition: custom

message type for controlling servo motors.

12 servo controller.bus_ servo control.set servo posit

ion: function used to set the servo angle.

13. rclpy.callback groups.ReentrantCallbackGroup:

supports concurrent callback handling.

14 rclpy.executors.MultiThreadedExecutor: multithreaded

executor in ROS 2 for handling concurrent tasks.

15 rclpy.node: node class in ROS 2.
16 speech: module related to large model voice interaction.

17 large models _msgs.srv: custom service types for large models.

18 large models.config: configuration file for large models.

@ VLLMWithCamera Class

display_size = [ f *6/4), (
class (Node):
f (self, name):
relpy.init()
me)
= queue.Queuve(maxsize=2)

-funning =
-action_finish =
-play_audio_fintsh =
s «bridge CvBridge()
self.client speech.OpenAIAPI(api_key, base_url)
self.declare_parameter( A
camera_topic = self.get_parameter( ).value

timer_cb_group = ReentrantCallbackGroup()

self.joints_pub = self.create_publisher(ServosPosition, ee |
self.tts_text_pub = self.create_publisher(String, ° )
self.create_subscription(Image, camera_topic, self.image_callback, 1)

s scription(String, ,» self.vllm_result_callback, 1)

, self.play_audio_finish_callback, 1, callback_group=timer_cb_group
)

e_ client(SetBool,

|

)
et_prompt_client.watt_for_service()
.timer = self.create_timer( , self.init_process, callback_group=timer_cb_group)

@) display size: defines the size of the display window.

11



=== Page 12 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

@ rclpy.init (): initializes the ROS 2 node.

@ super().init (name): calls the constructor of the superclass to

initialize the node with the specified name.

@ self.image queue: creates a queue to store image data, with a

maximum size of 2.

© self.vllm result: stores results received from the

agent_process/result topic.

© self.running: a flag variable used to control the running state of

the program.

@ timer cb group: creates a reentrant callback group for managing

timer callbacks.

self.joints pub: a publisher is created for sending robotic arm’s

joint position information.

@ self.tts text pub: a publisher is created for sending text data to

the text-to-speech node.

self.create subscription: creates subscribers to receive

image messages, VLLM results, and playback completion signals.

@ self.awake client and self.set_ model client: creates

service clients for triggering the wake-up and model configuration

services.

® self.timer: creates a timer that triggers the init process

function.

12



=== Page 13 ===
@ get_node_ state Method

62 def (self, request, response):
63 return response

return response: returns a response object.

@ init _process Method

(self):

self.timer.cancel()

msg = SetModel.Request()

msg.model = vllm_model

msg.model_type =

if os.environ[ N ] ==
msg.model = stepfun_vllm_model
msg.api_key = stepfun_api_key
msg.base_url = stepfun_base_url

else:
msg.model = vllm_model
msg.api_key vllm_apt_key

msg.base_url = vllm_base_url

self .send_request(self.set_model_client, msg)

msg = SetString.Request()
msg.data = VLLM_PROMPT

self .send_request(self.set_prompt_client, msg)

set_servo_position(self.joints_pub,
((1, ), ¢
speech.play_audto(start_audto_path)
threading. Thread(target=self.process, daemon= ).start()
self .create_service(Empty, f , self.get_node_ state)

self .get_logger().info('\033[1 \033 % t t')

@ self.timer.cancel (): stops the timer.

@ setModel.Request: creates a request message to configure the

model.

@ self.send request: sends the request to the corresponding

service.

@ set servo position: sets the initial joint positions of the robotic

arm.

13



=== Page 14 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

© speech.play audio: plays an audio file.

© threading.Thread: creates a new thread to run the process

function.

@ self.create service: registers a service to notify that the

initialization process is complete.

self.get logger () .info: logs informational messages to the

console.

@ send_request Method

(self, client, msg):
future = client.call_async(msg)

le rclpy.ok():
f future.done() and future.result():
return future.result()

@ client.call_ async (msg): makes an asynchronous service call.

@ future.done() and future.result (): check if the service call

is complete and retrieve the result.

@ vllm_result_callback Method

ck(self, msq):

self.vllm_result = msg.data

This callback receives results from the agent _process/result topic

and stores them in self.vllm_ result.

@ process Method

14



=== Page 15 ===
def process(self):
# box (]
while self.running:
image = self.image_queve.get(block=True)
if self.vllm_result:
msg String()
# self.get_l er().info('vlle_r
msg.data = self.vllm_result
self.tts_text_pub.publish(msg)
# if self

get_logger().info( "box
[int(box[o] * 6 i t¢ i) * 5 it [2] * 640), int(box[3] * 480)]
»x(O] = int(box[e]
0x1] int¢
int(bo
int(box[3] / 480 *
get_logger().info( "box
self.vllm_result
self.action_finitsh = True
self.play_audto_finish and self.actton_fintsh:
e play_audio_ finish False
self.actton_fintsh False

# msg = SetInt32.Request()

ig 1

nd_request(self.set
msg SetBool.Request()
msg.data True
self.send_request(self.awake client, msg)
t
# cv2.rectangle(image, (box[0], 1), ¢ (3) (255 Fal yr J

2.imshow( , cv2.cvtColor(cv2.resize(image, (display_size[0], display_size[1])), cv2.COLOR_RGB2BGR))

@ cv2.namedWindow and cv2.moveWindow: create and

position a window for image display.

@ self.image queue.get: retrieves image data from the

queue.

@ self.vllm result: ifaVLLM result is available, publishes

it to the text-to-speech node.

@ cv2.imshow: displays the image on the screen.

© cv2.waitKey: waits for a keyboard event.

@© cv2.destroyAllWindows: closes all OpenCV display

windows.

@ play _audio_callback Method

15



=== Page 16 ===
I .ay_al we: : is ck(self, msg):
self.play_audio finish = msg.data

4 iwennder Shenzhen Hiwonder Technology Co,Ltd

It sends a request to enable the wake-up feature once audio playback is

complete.
@ image_callback Method

It converts received ROS image messages to NumPy arrays and stores them in

the queue.

@ main Method

():
node = VLLMWithCamera(
executor = MultiThreadedExecutor()

executor.add_node(node)
executor.spin()
node.destroy_node()

@ Create an instance of the VLLMWithCamera node.
@ Use a multithreaded executor to manage the node's tasks.
@ Callexecutor.spin() to start processing ROS events.

@ Upon shutdown, the node is properly destroyed using

node.destroy node().

16


