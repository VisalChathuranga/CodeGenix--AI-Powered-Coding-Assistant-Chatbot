
=== Page 1 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd

Smart Home Assistant in Embodied Al
Applications

The large model used in this lesson operates online, requiring a stable

network connection for the main controller in use.

1 Brief Overview of Operation

Once the program starts running, the Six-Microphone Circular Array will
announce “I’m Ready,” hereafter called the voice device. To activate the voice
device, speak the designated wake words: “Hello Hiwonder.” Upon
successful activation, the voice device will respond with “I’m Here.” After
activation, voice commands can be used to control the robot. For example,
issuing the instruction:

"Go to the kitchen to see if the door is closed, then come back and tell
me." Upon receiving a command, the terminal displays the recognized speech
content. The voice device then verbally responds with a generated answer and

the robot simultaneously executes the corresponding action.

2 Getting Started

2.1 Version Confirmation

Before starting this feature, verify that the correct microphone

configuration is set in the system.

1) Log in to the machine remotely via NoMachine. Then click the desktop

icon to access the configuration interface.

2) First, verify the system language setting.



=== Page 2 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd

as [Eels >)

3) For the Six-Microphone Circular Array, select xf as the microphone

type as shown in the figure.

AP Name HW-24347055

Version V1.1.1 2025-05-20

abel EE
ROS2 Humble

4) After making the appropriate selection, click Save.

5) A “Save Success” message will confirm that the configuration has

been stored in the system environment.



=== Page 3 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Save Success

6) Then, click Quit to close the interface.

2.2 Configuring the Large Model API-KEY

Open a new command-line terminal and enter the following command to

access the configuration file.

vim /home/ubuntu/ros2_ws/src/large_models/large_models/large_models/config.py

Refer to the tutorial under “Al Large Language Model Course / 1 Large
Language Model Basic Courses/1.1 Large Language Model Courses/1.1.2
Large Language Model Deployment” to obtain the API keys for vision language
model. For the vision language model, acquire the API key from the
OpenRouter official website and assign it to the vllm_api_key variable. For
the large language model, obtain the API key from the OpenAl official website
and assign it to the 1lm_api_key variable. Ensure that the keys are inserted
in the designated positions, as indicated by the red boxes in the reference

image.



=== Page 4 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

25, vllm_apt_key =
26 vllm_base url =
27 villm_model =

9° 1Lm apt key =

© Llm_base_url =
1 Llm_model =

2 openai_vllm_model =

3 openai_tts_model =

4 openai_asr_model =
openai_voice_model =

3 Navigation Map Construction

Before enabling this feature, a map must be created in advance. Please
refer to “ROS2 Courses / 5 Mapping & Navigation Course / Mapping” for

detailed instructions on how to build the map.

4 Enabling and Disabling the Feature

@ 1. Command input is case-sensitive and space-sensitive.

2. The robot must be connected to the Internet, either in STA (LAN)

mode or AP (direct connection) mode via Ethernet.

1) Open the command line terminal from the left side of the system

terrace, In the terminal window, enter the following command
and press Enter to stop the auto-start service

sudo systemctl stop start_app_ node.service

stop start app node.service

2) Enter the following command and press Enter to launch the feature.

ros2 launch large models examples vllm_navigation.launch.py

map:=map_ 01

Launch Large models examples vlLm navigation. Launch.py map:=map 01

3) Once rviz is launched with the map, click on the 2D Pose Estimate icon

4



=== Page 5 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

to initialize the robot's position and orientation based on its actual location on

the map.

/home /ubuntu/ros2_ws/install fnavigation/share/navigation/rviz/navigation_controller.rviz* - RVIz

Measure | 20 Pose Estimate 20Goal Pose — PublishPoint  Mav2col >

he.

Reset 27 fp

4) When the terminal displays the corresponding output shown in the
figure and the device responds with "I’m Here", it indicates successful

activation.

[agent_process-6] [INFO] [1742389935.057819613] [agent_process]:

[agent_process-6] [INFO] [1742389935.273320881] [agent_process]:

Speak a command such as “Go to the kitchen to see if the door is
closed, then will come to tell me.” The voice device will capture the speech,

and the large language model will process the command.

5) Upon successful recognition by the speech recognition service of
cloud-based large speech model, the parsed command will be displayed under

the publish _asr_result output in the terminal.

[vocal_detect]:

[vocal_detect]:

vocal_detect]:

vocal_detect]: asr time: 0.86

[vocal_detect]: Go to the kitchen to see if the door is closed, then will come to tell me.

6) Upon receiving user input shown in the figure, the terminal will display
output indicating that the cloud-based large language model has been

successfully invoked. The model will interpret the command, generate a

5



=== Page 6 ===
4 iweander Shenzhen Hiwonder Technology Co,Ltd

language response, and execute a corresponding action based on the

meaning of the command.

@ The response is automatically generated by the model. While the
semantic content is accurate, the wording and structure may vary due to

randomness in language generation.

[vllm_navigation]: vllm action: ["move('kitchen')", "vision('Is the door closed?')", "move('origin')", 'play_audio()']

[vllm_navigation]: position: kitchen

7) The robot will move to the designated “kitchen” location as defined in

the program, detect whether the door is closed.

home /ubuntu/ros2_ws/install/navigation/share /navigation/rviz/navigation_controller.rviz* - RVIz
File Panels Help

Pointeract ™ Move Camera Tselect Focus Camera Measure #20 PoseEstimate £ 20GoalPose  @ PublishPoint Nav2Goal + -

® Global Options
¥ Global Status: Ok

Identh camirablimaae raw

leTa: os
IDistance remaining: 0.00 m
|Time tak Os
IRecoveri °

Reset

Waypoint / Nav Through Poses Mode

PF a

8) Then return to the original position and state whether “the door is

closed.”



=== Page 7 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

/home/ubuntu/ros2_ws/install/navigation/share/navigation/rviz/navigation_controller.rviz* - RVIz

lle Panels Help
ijinteract |< move camera (JSetect. Focus Camera = Measure 7 2 Pose Estimate

Displays

© Global Options

~¥ Global Status: Ok
> Grid

Pause

9) When the terminal shows the output shown in the figure indicating the
end of one interaction cycle, the system is ready for the next round. To initiate

another interaction, repeat step 5 by speaking the wake words again.

S_node-/ 4202411 70 s_ z
tts_no a 7] INFO} [17 8] [tts node}:
tts node-7] [INFO] [17 2) [tts_node]: Speech sy inthes izer is eles ed.

[vocal detect 5] [INFO] [17425 8064206] i vocal_detect]:

10)To exit the feature, press Ctrl+C in the terminal. If the feature does not

exit immediately, press Ctrl+C multiple times.

5 Project Outcome

Once the program and map are fully loaded, you may speak a command
such as: “Go to the kitchen to see if the door is closed and let me know
when you come back.” The robot will navigate to the predefined “kitchen”
location, verify the door status, then return to the starting point and report the

outcome.



=== Page 8 ===
Hivwonder Shenzhen Hiwonder Technology Co,Ltd

Jhome/ubuntu/ros2_ws/install/navigation/share/navigation/rviz/navigation_controller.rviz* - RVIz

Tsetect FocusCamera Measure 4 2DPoseEstimate 4 20GoalPose @ PublishPoint = Nav2Goal =

4

6 Modifying Navigation Locations

To change the robot’s navigation targets, modify the relevant parameters

in the following file:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_exam

ples/vilm_navigation.py

1) Begin by launching the program and displaying the map in rviz
following step 4 above. Then, click on “2D Goal Pose’ in the rviz interface to

set the desired navigation target on the map.




=== Page 9 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd

home /ubuntu/ros2_ws/install/navigation/share/navigation/rviz/navigation_controller.rviz* - RVIz
Eile Panels Help

Pyinteract ‘Move camera [Select FocusCamera saMeasure 7 20Posetstimate [ 2DGoalPose | @ Publ

+ @ Global Options s 1

2) Return to the terminal to view the published goal parameters. Once

you obtain the target coordinates, you can fill in the x and y values and related

parameters accordingly.

Locate the corresponding section of the code shown below, and fill in your

target location parameters after the appropriate location name.

position dict = {

The positions of different navigation targets in the program are relative to

the robot's starting point during the map-building process. The five parameters

represent:
x: position on the x-axis (meters)

y: position on the y-axis (meters)



=== Page 10 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

roll: rotation around the x-axis (degrees)
pitch: rotation around the y-axis (degrees)
yaw: rotation around the z-axis (degrees)

Taking “kitchen” as an example, if the robot’s target position is set to [1.45,
-0.29, 0.0, 0.0, 0.0], it means that the robot will navigate to the "kitchen"

location on the map.
To modify the robot’s target orientation:

The retrieved quaternion has been printed as Orientation (0, 0,
-0.379167, 0.925328) = Angle: -0.777791 in radians. Convert this quaternion
to Euler angles (roll, pitch, yaw), and the result is approximately roll ~ 0°,

pitch ~ 0°, and yaw ~ -44.56°, or converting the radian value directly to

degrees gives —44.58°.

The final modified target position for “kitchen” is [1.45, -0.29, 0.0, 0.0, -44.58].

7 Program Brief Analysis

7.1 Launch File Analysis

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_e

xamples/vilm_navigation.launch.py

@ Import Libraries

1 import os

2 from ament_index_python.packages import get_package_share_directory

3

4 from Launch FOS. at tions import Node

5 from Launch actions import PushRosNamespace

6 from Launch togigr rt LaunchDescription, LaunchService

7 from Launch.substitutions import prvemengsmma <-ma

8 from Launch. Launch de ipt urce mport PythonLaunchDescriptionSource

9 from ch.actions import DeELaraLsGnchArgument IncludeLaunchDescription, GroupAction, OpaqueFunction, TimerAction,
" ExecuteProcess

10



=== Page 11 ===
HSI VW/EX2MOECT Shenzhen Hiwonder Technology Co,Ltd

@ os: used for handling file paths and operating system-related

functions.

@) ament index python.packages.get package share direc

tory: retrieves the share directory path of ROS 2 package.

(6) launch_ros.actions.Node: used to define ROS 2 nodes.

@ tlLaunchDescription, LaunchService: used to define and start

the Launch file.

© launch description sources

PythonLaunchDescriptionSource: enables the inclusion of other

Launch files.

@ launch.actions.IncludeLaunchDescription,

DeclareLaunchArgument, OpaqueFunction: used to define actions and

arguments within the Launch file.

@ Definition of the launch_setup Function

11



=== Page 12 ===
Hivwonder Shenzhen Hiwonder Technology Co,Ltd

def Launch_setup(context):
jetauto_description_package_path = get_package_share_directory(' jetaut je ipt )
slam_package_path = get_package_share_directory(
navigation_package_path = get_package_share_directory( navigation’)
large_models_package_path = get_package_share_directory(' Larae rd )

mode = LaunchConfiguration( ‘mode’, default=1)
mode_arg = DeclareLaunchArgument( ' , default_value=mode)

map_name = LaunchConfiguration( ', default='; ').perform(context)
robot_name = LaunchConfiguration( ' t_name', default=os.environ[ 'HOST'])
master_name = LaunchConfiguration( ‘mast me', default=os.environ[ 'MASTER'])
map_name_arg = DeclareLaunchArgument( ‘\ , default_value=map_name)
master_name_arg = DeclareLaunchArgument( 'mastes me', default_value=master_name)
robot_name_arg = DeclareLaunchArgument( t_name', default_value=robot_name)

navigation_lLaunch = IncludeLaunchDescription(
PythonLaunchDescripttonSource(os.path. join(navigatton_package_ path,
Launch_arguments={
sim's 'f e',
: map_name,
t : robot_name,
ame’: master_name,
jse_teb': true',
}.items(),
)
navigation_controller_node = Node(
package=' Large_mod: examples',
executable=' gat rt er',
output=' f J
parameters=[{'map_frame': ‘1 »n 9 's "Sn 1c }]

)

rviz_node = ExecuteProcess(
emd=['rviz2', z2', ‘-d', os.path.join(navigation_package_path,
output=

Large_models_launch = IncludeLaunchDescription(
PythonLaunchDescripttionSource(

os.path. join(large_models_package_path, tart h.py')),
launch_arguments={' je': mode}.items(),
)
vllm_navigation_node = Node(
package=' Lar models_examples',
executable=' 1_na jation',
output='sc .
)
return [
mode_arg,

map_name_arg,

@ This function is used to configure and initialize launch actions.

@ mode = LaunchConfiguration('mode', default=1) defines a

Launch argument named mode with a default value of 1.

@ mode _ arg = DeclareLaunchArgument ('mode',

default value=mode) declares the mode argument and includes it in the

Launch description.

@ navigation package path, large models package path:

retrieves the shared directory path of the navigation and large models

package.

©)

navigation launch: includes the file robot. launch. py and the

file bringup. launch.py using IncludeLaunchDescription.

12



=== Page 13 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

© large models launch: includes the Launch file

start.launch.py fromthe large models package using

IncludeLaunchDescription and passes the mode argument to it.

@ vllim navigation node: defines a ROS 2 node from the

large models examples package, executes the executable files from the

villm_navigation.py, and prints the node's output to the screen.

vllm_ navigation _node: defines a ROS 2 node from the

large models examples package, executes the executable files from the

villm_navigation.py, and prints the node's output to the screen.

@ navigation controller node: defines a ROS 2 node from the

large _ models examples package, executes the executable files from the

navigation controller.py to enable navigation control.

rviz_ node: defines a ROS 2 node from the navigation package,

executes the navigation _controller.rviz files to enable the displaying

of navigation control.
11 The function returns a list of all defined Launch actions.

@ Definition of the generate launch description Function

74 def generate_launch_description():

75 return LaunchDescription([

76 OpaqueFunction(function = Launch_setup)
7 6 ()

@_ This function is responsible for generating the complete Launch

description.

@ The launch setup function is incorporated using

OpaqueFunction.

13



=== Page 14 ===
HIVVEXMCOECT Shenzhen Hiwonder Technology Co,Ltd

@ Main Program Entry

791f name == '_ ma H
80 # create a LaunchDescription object

81 ld = generate_lLaunch_description()
82

83 ls = LaunchService()

84 ls.include_lLaunch_description(ld)
85 ls.run()

@ 1d= generate launch description() generates the Launch

description object.

@ 1s = LaunchService() creates the Launch service object.

@ 1s.include launch description (1d) adds the Launch

description to the service.

@ 1s.run() starts the service and execute all Launch actions.

7.2 Python File Analysis

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_e

xamples/vilm_navigation.py

@ Import the necessary libraries

5S import re

6 import time

7 import json

8 import rclpy

9 import threading

10 from speech import speech

11 from rclpy.node import Node

12 from sensor_msgs.msg import Image

13 from std_msgs.msg import String, Bool

14 from std_srvs.srv import Trigger, SetBool, Empty

15

16 from lLarge_models.config import *

17 from Large_models_msgs.srv import SetModel, SetContent, SetString, SetInt32
18

19 from interfaces.srv import SetPose2D

20 from rclpy.executors import MultiThreadedExecutor

21 from rclpy.callback_groups import ReentrantCallbackGroup

an

14



=== Page 15 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

@ json: used for handling data in JSON format.
@ time: manages execution delays and time-related operations.

@  xrclpy: provides tools for creating and communicating between ROS

2 nodes.

@ threading: enables multithreading for concurrent task processing.
© speech: handles modules related to large model voice interaction.
© std_msgs.msg: contains standard ROS message types.

@M rclpy. callback _groups.ReentrantCallbackGroup:

supports concurrent callback handling.

rclpy.executors.MultiThreadedExecutor: multithreaded

executor in ROS 2 for handling concurrent tasks.

@ large models msgs.srv: custom service types for large models.

Large _models.config: configuration file for large models.

@ PROMPT String

15



=== Page 16 ===
M4 iIiVWE) mM | ft Shenzhen Hiwonder Technology Co,Ltd
75

LLM_PROMPT = '''

76 **Role

77 You are a smart navigation vehicle equipped with a camera and speaker. You can move to different
places, analyze visual input, and respond by playing audio. Based on user input, you need to
generate the corresponding JSON command.

78

79 **Requirements

80 - For any user input, look up corresponding functions from the Action Function Library, and
generate the proper JSON output.

81 - For each action sequence, include a concise (5-20 characters) and witty, varied response to make
the interaction Lively and engaging.

82 - Output only the JSON result, no analysis or extra text.

83 - Output format:

845

85 Pactton" s. [xxc"., "sx",
86 "response": "xx"

87 }

88

89 **Special Notes

90 The "action" field contains an ordered list of function names to be executed in sequence. If no
matching function is found, return: "action": [].

91 The “response” field should contain a carefully crafted, short, humorous, and varied message (5-20
characters).

92

93 **Acttion Function Library

94 Move to a specified place: move('kitchen')

95 Return to starting point: move('origin')

96 Analyze current view: viston('What do you see?')

97 Play audio response: play_audto()

98

@ VLLMNavigation Class

58 class VLLMNavigation(Node):
59 def _init_(self, name):

6e rclpy.init()

61 super().__tntt__(name)

62

63 self.action = []

64 self.response_text = |'

65 self.Ulm_result =

66 self.play_audto_fintsh = False

67 # self.Ulm_result = ‘{\'action\':[\'move(\"AJG\")\', \'vision(\"AMARAX\")\', \'move(\"BUR\")\', \'play_audio()\'], \'response\':\'S.£!\'}'
68 self.running = True

69 self.reach_goal = False

78 self.interrupt = False

71

72 timer_cb_group = ReentrantCallbackGroup()

73 self.tts_text_pub = self.create_publisher(String, ‘tts_node/tts_text’, 1)

74 # self.create_subscription(Image, ‘depth_cam/rgb/image_raw', self.image callback, 1)

75 self.create_subscriptton(String, ‘agent_process/result', self.lUm_result_callback, 1)

76 self.create_subscriptton(Bool, ‘vocal_detect/wakeup', self.wakeup_callback, 1)

77 self.create_subscriptton(Bool, ‘(ts _node/play_finish’, self.play_audto_fintsh_callback, 1, callback_group=timer_cb_group)
78 self.create_subscriptton(Bool, ‘navigatlon_controller/reach_goal’, self.reach_goal_callback, 1)
79 jake_clitent = self.create_cltent(SetBool, ‘vocal_detect/enable_wakeup')

80 -awake_client.watt_for_service()

81 self.set_mode_client = self.create_client(SetInt32, ‘vocal _detect/set_mode')

82 self.set_mode_client.wait_for_service()

83 self.set_model_client = self.create_client(SetModel, ‘agent_process/set_model')

84 self.set_model_client.wait_for_service()

8s self.set_prompt_client = self.create_client(SetString, ‘agent_process/set_prompt')

86 self.set_prompt_client.wait_for_service()

87 self.set_vllm_content_client = self.create_client(SetContent, ‘agent_process/set_vllm_content’)
88 self.set_vl1m_content_client.wait_for_service()

89 self.set_pose_cltent = self.create_client(SetPose2D, ‘navigation_controller/set_pose')

90 self.set_pose_client.wait_for_service()

91

92 self.timer = self.create_timer(0.0, self.intt_process, callback_group=timer_cb_group)

aa

@ get_node_state Method

d&f get_node_state(self, request, response):
return response

return response: returns a response object.

@ init process Method

16



=== Page 17 ===
Hivwonder Shenzhen Hiwonder Technology Co,Ltd

def init_process(self):
self.timer.cancel()

msg = SetModel.Request()

msg.model = Llm_model

msg.model_type = ‘Lim

msg.api_key = api_key

msg.base_url = base_url
self.send_request(self.set_model_client, msg)

msg = SetString.Request()
msg.data = LLM_PROMPT
self.send_request(self.set_prompt_client, msg)

init_finish self.create_client(Empty, ‘navigation_controller/init_finish' )
init_finish.wait_for_service()

speech.play_audio(start_audio_path)

threading. Thread(target=self.process, daemon=True).start()
self.create_service(Empty, ‘~/init_finish', self.get_node_state)

self .get_logger().info('\033[1;32m%s\033[0m' % ‘start')

self .get_logger().info('\033[1;32m%s\033[0m' % LLM_PROMPT)

@ self.timer.cancel(): cancels the timer.

@ SetModel.Request (): creates a request message to set the LLM

model.

@) SetModel.Request: creates a request for SetModel service.

@ msg.model_ type = '11lm': specifies the model type as 'l 1m’.

© self.send request (self.set model client, msg): sends

the model configuration request through the set_model_client.

© SetString.Request: creates a request message to set the prompt

string.

@® self. send request (self.set prompt client,msg): sends

the model configuration request through the set_ prompt client.

Empty .Request: request message used to clear the current

conversation history.

@ self.send request (self.clear chat client, msg): sends

the request through the clear_chat_client to reset chat context.

17



=== Page 18 ===
4 IV/EM | er Shenzhen Hiwonder Technology Co,Ltd

self.create client (Empty,

‘object _transport/init finish"): creates a service client for calling

the object _transport/init finish endpoint.

11 init finish.wait for service (): waits for the

init finish service to become available.

12 self.send_ request (self.enter client,

Trigger.Request () ): sends a Trigger request through the enter client

to initiate the process.

13. speech.play audio: plays an audio cue.

14. threading.Thread: launches the main logic in a new thread.

15 self.create service: creates a service to signal the completion

of initialization.
16 self.get logger () .info: prints log messages.

@ send_request Method

118 def send_request(self, client, msg):

119 future = client.call_async(msg)

120 while rclpy.ok():

121 if future.done() and future.result():
122 return future.result()

1272
@ client.call_ async (msg): makes an asynchronous service call.

@ future.done() and future.result (): check if the service call

is complete and retrieve the result.

@ 11m_result_callback Method

128 def Llm_result_callback(self, msg):
129 self.llm_result = msg.data
130

18



=== Page 19 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

This callback receives results from the agent _process/result topic

and stores them in self.1lm_ result.

@ wakeup_callback Method

124 def wakeup callback(self, msg):
125 self.get_Logger().info( E'S)
126 self.interrupt = msq.data

This method is invoked when the user activates the system via voice to
receive and process the wake-up signal from the vocal _detect/wakeup

topic.
@ move (self, position) Method
( Parameter receiving: receives a location name, such as "kitchen".

@ Position Lookup p = position dict[position] : retrieves the

corresponding coordinate and position data from the position dict

dictionary.

@ Message Construction: creates a Set Pose2D. Request () message

and sets the values for x, y coordinates, and roll, pitch, yaw angles.

@ — Service Invocation

self.send_ request (self.set pose client, msg): sends the request

to the navigation controller using set_ pose client.

This method enables the robot to navigate between predefined locations,

serving as a fundamental function for spatial movement tasks.

@ play audio(self) Method

142 def play_audio(self):

143 msg = String()

144 msg.data = self.response_text

145 self.get_logger().info(f tex )
146 while not self.play_audio_fintish:

147 time.sleep( )

148 self.play_audto_finish =

149 self.tts_text_pub.publish(msg)

150 self.response_text =
ac4

19



=== Page 20 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

This method plays the text content stored in self.response text.

() Message Creation ‘msg = String()’: initializes a String type

message.

@ Logging ‘msg.data = self.response text’: logs the content to

be played.

@ Waiting ‘while not self.play audio finish’: enters a loop

that waits for the previous audio playback to complete.

@ State Reset ‘self.play audio finish = False’: resets the

playback status with self.play audio finish = False.

© Publishing ‘Self.tts text pub.publish (msg) ’: publishes the

message to the tts text pub topic to trigger text-to-speech conversion.
© self. response text = '': clears self.response text.

This method enables the robot to deliver voice feedback, allowing it to

communicate with the user through speech.
@ reach_goal_callback(self, msg) Method

( Parameter Receiving: receives a Boolean message indicating

whether the robot has reached its destination.

@ State Update: updates the internal navigation status by assigning the

message data to self.reach_goal.

This callback handles feedback from the navigation controller and informs

the system when the robot completes a movement task.
@ vision(self, query) Method

This method processes visual queries using the Vision-Language Large

20



=== Page 21 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Model (VLLM).
( Parameter Receiving: accepts a query string, such as "What do you

see?".

@ Message Construction: creates a SetContent .Request ()

message containing the API key, base URL, model name, prompt string, and

query content.

@ Service Invocation: sends the request to the vision-language large

model service via set_vllm_content_client.
@ Response Return: returns the response message from the VLLM.

This method equips the robot with visual perception capabilities, allowing it

to understand and describe its visual surroundings.
@ play audio finish_callback(self, msg) Method

This method handles the callback notification indicating the completion of

audio playback.

@® Parameter Receiving: receives a Boolean message that indicates

whether audio playback is complete.

®@ State Update: updates the playback status by assigning the message

data to self.play audio finish.

@ Wake-up Configuration: constructs a SetBool.Request () message

to enable the wake-up function.

® Mode Configuration: constructs a Set Int32.Request () message to

set the interaction mode to 1.

This method handles post-playback processing and prepares the system

for the next user command, supporting continuous interaction.

21



=== Page 22 ===
HIVVEXMCOECT Shenzhen Hiwonder Technology Co,Ltd

@ process Method

def process(self):
first = True
while self.running:
if self.1llm_result:

self.interrupt = False

msg = String()

Af ‘action’ in self.llm_result: # RI RAXIMBITAIR BAZ PDA
result = json. loads(self.llm_result[self.llm_result.find('{'):self.llm_result.find('}' )+1))
if ‘response’ itn result:

msg.data = result[' response’ ]
self .tts_text_pub.publish(msg)
Af ‘action’ in result:
action = result['action']
self .get_logger().info(f'vlim action: {actton}')
for a in action:
Af ‘move’ in a:
self.reach_goal False
eval(f'self.{a}')
while not self.reach_goal:
Af self.interrupt:
self .get_logger().info(' interrupt’)
break
# self.get_logger().info('watting for reach goal')
time.sleep(0.01)
elif ‘vision’ in a:
res eval(f'self.{a}')
self.response_text = res
self .get_logger().info(f'vllm response: {res}')
elif ‘play_audio’ in a:
eval(f'self.{a}')
while not self.play_audio_finish:
time.sleep(1)
if self.interrupt:
self .get_logger().info( interrupt’)
break

else: * RAXMHITN, RAF
msg.data = self.llm_result
self.tts_text_pub.publish(msg)

self.actton_finitsh = True

self.Ulm_result = °

else:
time.sleep(0.01)

if self.play_audio_finish and self.action_finish:
self.play_audio_finish = False

self.action_finish False

msg = SetBool.Request()

msg.data = True

self.send_request(self.awake_client, msg)

# msg SetInt32.Request()

# msg.data

# self.send_request(self.set_mode_client, msg)

rclpy.shutdown()

@® Check LLM Result
if self.1llm_result: check whether self.11m_ result contains
content. If not empty, it indicates that a new result from the LLM needs to be

processed. Otherwise, the system enters a short sleep to wait for new results.

@ > Check for Action Commands

if 'action' in self.1lm_result: if the returned result contains the
"action" field, it means that in addition to the response text, there are action

commands to execute.

@ Extract and Parse JSON Data

result =

json.loads (self.llm_result[self.1llm_result.find('{'):self

22



=== Page 23 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

.1llm_result.find('}')+1]): use string search to locate the start and

end of the JSON section, and parse it into a dictionary using j son. loads to

extract fields such as "response" and "action".

@ Handle Text Response and Execute Actions

If the parsed result contains "response", assign the content to a
message and publish it to the tts text pub topic to trigger TTS playback.

If "action" is present, iterate through the action list:

a. Move command: If the action string contains "move", first set
self.reach goal to False, call the corresponding move function using
eval to execute dynamically, and then loop until self.reach_goal becomes
True, which indicats that the robot has reached the goal. During this period,
monitor self.interrupt to allow interruption.

b. Vision detection: If "vision" is present, execute the corresponding
vision function, assign the returned result to self.response_ text, and log
the result.

c. Audio playback: If "play audio" is present, directly call the

corresponding audio playback function.

© Interrupt Check

During each action execution, continuously monitor the
self.interrupt flag. If an interrupt is triggered while waiting or executing
an action, the current action is interrupted and the corresponding loop is exited

in time.

© Mark as Complete and Switch Mode

Regardless of whether actions are included, after processing the current

LLM result, set sel£.action_finish to True and clear

self.11lm_result. Later in the loop, when both

J7+£

self.play audio finishand self.action finish are True, reset

these two flags and send a mode-switch request via set_mode client,

23



=== Page 24 ===
4 IV/EM | er Shenzhen Hiwonder Technology Co,Ltd

entering the next state. Finally, wnen self. running becomes False, the

loop exits and the ROS system is shut down.
@ main Method

223 def main():

224 node = VLLMNavigation( )
225 executor = MultiThreadedExecutor()

226 executor.add_node(node)

227 executor.spin()

228 node.destroy_node()

229

Create an instance of the VLLMObjectTransport node.

A multithreaded executor is used to handle the node’s tasks.

Call executor.spin() to start processing ROS events.

Se © 8 ©

Upon shutdown, the node is properly destroyed using

node.destroy node().

File Path:

/home/ubuntu/ros2_ws/src/large_models_examples/large_models_e

xamples/navigation_controller.py

@ Import the necessary libraries

6 import math

7 import rclpy

8 Lmport numpy as np

9 from rclpy.node import Node
10 import sdk.common as common

11 from std_msgs.msg import Bool
12 from std_srvs.srv import Trigger, Empty
13 from rclpy.duration import Duration

14 from interfaces.srv import SetPose2D

15 from geometry_msgs.msg import PoseStamped

16 from rcl_interfaces.srv import GetParameters

17 from rclpy.executors import MultiThreadedExecutor

18 from visualization_msgs.msg import Marker, MarkerArray

19 from rclpy.callback_groups import ReentrantCallbackGroup

20 from nav2_simple_commander.robot_navigator import BasicNavigator, TaskResult

@ math: used for angle conversion, e.g.,

math.radians (data.rol1), to convert degrees to radians.

@  xrclpy: provides tools for creating and communicating between ROS

24



=== Page 25 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

2 nodes.

@ rclpy.node.Node: base class for ROS 2 nodes.

@ rclpy.duration.Duration: handles ROS 2 time and duration,

used for navigation timeout calculation, for example,

Duration.from msg (feedback.navigation time) >

Duration (seconds=600.0).

@ rclpy. callback _groups.ReentrantCallbackGroup:

supports concurrent callback handling.

© nav2_ simple commander.robot navigator: provides

navigation functionality encapsulation.

@ std_msgs.msg.Bool: message type for boolean values.

std_srvs.srv.Trigger, Empty: standard service types, used to

create services like self.create service (Empty, '~/init finish',

self.get_ node state).

@ interfaces.srv.SetPose2D: custom service type for setting

navigation goal poses, for instance, self.create service (SetPose2D,

'~/set_pose', self.move srv_ callback).

geometry msgs.msg.PoseStamped: pose message with

timestamp.

11 rcl_interfaces.srv.GetParameters: parameter service type.

12 visualization msgs.msg.Marker, MarkerArray: messages

for visualization markers.

25



=== Page 26 ===
HIVVEXMCOECT Shenzhen Hiwonder Technology Co,Ltd

13. sdk.common: custom SDK utility functions.

14 numpy (np): supports matrix and vector operations.

@ NavigationController Class

22 class NavigationController (Node):

23 markerArray = MarkerArray()

24

25 def int (self, name):

26 relpy.init()

27 super().__tntt__(name, allow_undeclared_parameters= , automatically_declare_parameters_from_overrides= )
28

29 self.goal_pose = PoseStamped()

30 self.navigator = BasicNavigator()

31

32 2Lf.map_frame = #self.get_parameter('map_frame').value

33 Uf.nav_goal = #self .get_parameter('nav_goal').value

34

35 timer_cb_group = ReentrantCallbackGroup()

36 self.goal_pub = self.create_publisher(PoseStamped, 5 5)
37 self.nav_pub = self.create_publisher(PoseStamped, self.nav_goal, 1)
38 2Lf.mark_pub = self.create_publisher(MarkerArray,
39 self.reach_pub = self.create_publisher(Bool, » 1)

40

41 elf.create_subscription(PoseStamped, self.nav_goal, self.goal_callback, 1, callback_group=timer_cb_group)
42

43 elf.create_service(SetPose2D, » self.move_srv_callback)
44

45 self navigator .waituntilNav2Active()

46 elf.create_service(Empty, t » Self.get_node_ state)

47 self.get_logger().info( \o33 \o33 * )

48

49 def get_node_state(self, request, response):

50 return response

51

52 def send_request(self, client, msg):

53 future = client.call_async(msg)

54 while rclpy.ok():

55 if future.done() and future.result():

56 return future.result()

57

58 def move_srv_callback(self, request, response):

59 self.get_logger().info( )

60

61 marker_Array = MarkerArray()

62 marker = Marker()

63 marker.header.frame_id = self.map_frame

64 marker.action = Marker.DELETEALL

65 marker_Array.markers.append(marker)

66

67 elf.mark_pub. publish(marker_Array)

68

69 markerArray = MarkerArray()

7° pose = PoseStamped()

@® rclpy.init (): initializes the ROS 2 system.

@ super(). init (name): call the parent Node class constructor to

create a ROS 2 node.

@ self.create subscription: subscribe to navigation goal poses.

@ self. create client: create service clients.
©) self.timer: create a timer.

© self.goal_pose: store the navigation goal pose.

@ self.navigator: navigator object.

26



=== Page 27 ===
4 iwennder Shenzhen Hiwonder Technology Co,Ltd

OQ)

11

12

13

14

self.map frame: name of the map coordinate frame.

self.nav_goal: topic name for navigation goals.

self.goal_pub: publisher for goal poses.

self.nav_pub: publisher for navigation goals.

self.mark_ pub: publisher for markers.

self.reach_pub: publisher for goal-reached messages.

self.create service: create service servers.

@ send_request Method

0)

This method creates a loop to continuously check if the service call is

complete.

@

@

@

©)

result.

rclpy.ok(): ensures the ROS 2 system is still running.

future.done (): checks whether the service call has completed.

future.result (): retrieves the result of the service call.

Once the service call completes and the result is valid, return the

@ move_srv_callback Method

27



=== Page 28 ===
Fliwonder Shenzhen Hiwonder Technology Co,Ltd

jest, response):
“get. ioe Os tn Stet
60
61 marker_Array = MarkerArray()
62 marker = Marker()
63 marker. header. frame_td = self.map_frame
64 marker.action = Marker.DELETEALL
65 marker_Array.markers.append(marker)
66
67 elf.mark_pub. publish(marker_Array)
68
69 markerArray = MarkerArray()
7° pose = PoseStamped()
71 pose. header. frame_id = self.map_frame
72 pose am f navigator .get_clock().now().to_msg()
73 dat data
74 q rpy2qua(math.radtans(data.roll), math.radtans(data.pitch), math.radians(data.yaw))
75 pose positton.x = data.x
76 pose.pose.position.y = data.y
77 pose.pose.ortentation = q
78
1s th numbe display)
80
81 f.map_frame
82
83 e = mar a -MESH_RESOURCE
84 esou
85 = mar rker -ADD
86
87
88
89
98
91 P- random. choice(range( ), stze=3))
92
93 ar r = color[e) /
94 marker.color.g = color[i] /
95 marker.color.b = color[2] /
96 # marker. Ut me = rospy.Ouration(10) # SmBYia], MAAMRU—BRM(display time. If not set, it will be kept by default)
ca # {ZB A(posttion posture
98 marker.pose.posttton. pose.pose.positton
99 marker .pose. position pose. pose. posttton.y y
100 marker .pose.orientation = pose.po: ntatio
101 markerArray.markers.append(marker oi

This is the callback function for the ~/set_pose service. It is used to
receive external requests to set a new navigation goal and to visualize the

target point in visualization tools, for example, RViz.

@ Clear Existing Markers

Create aMarkerArray object named marker Array. Construct a

Marker object and set its action to DELETEALL.
Add this Marker to marker Array.markers and publish it via
self.mark_pub to clear any previously existing markers.

@ Construct a New Navigation Goal (PoseStamped)

pose = PoseStamped(): create a PoseStamped message object

named pose.

pose.header.frame id=self.map frame: set its coordinate frame

toself.map frame ("map").
Fill pose. header. stamp with the current timestamp.

data = request.data: extract position data x, y and Euler angles roll,

pitch, yaw from the request.

28



=== Page 29 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

q = common.rpy2qua (): since ROS requires orientation in quaternion

form, convert the Euler angles using the common. rpy2qua function after

converting to radians, and assign the result to pose. pose. orientation.
@ Construct and Display Goal Marker

Create another MarkerArray object named markerArray for

displaying the new goal.
marker = Marker (): create a Marker object.
header.frame id = self.map frame: set the coordinate system

marker.mesh resource =

"nackage://example/resource/flag.dae": set the mesh resource to

"package: //example/resource/flag.dae", a 3D model representing

the goal position.

marker.action = marker.ADD: indicate that this is a new marker to

add.
Set the marker's scale and transparency (alpha = 1.0).

Generate three random RGB color values using numpy, and normalize

them by dividing by 255.
Set the marker's position and orientation to match those in pose.

Add the Marker to markerArray.markers and publish it using

self.mark_pub, then the goal point appears in RViz.
@ Publish Navigation Goal

self.nav_pub.publish (pose): publish the constructed pose
message to the /nav_goal topic so other nodes or internal callbacks like
goal_callback can receive the new goal.

©) Return Service Response

29



=== Page 30 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

Set response.success = True and response.message =

"navigation pick" to indicate the service call succeeded, then return the

response.

@ goal_callback Method

110 def wr elf, neg)

qi # ee te FF, ( ain the navigation point to be published

112 -get_ ere. chten \033 \9 % str(msg))

113

114 elf.navigator.goToPose(msg)

115 i=

116 # feedback = self.navigator.getFeedback()

117 a gl_time = Duration. from_msg(feedback.estimated_time_remaining) .nanosecond
118 a catt sgger().info 633[1; 32m%s\033[6m total_time'

119 while at e F. navigator: isTaskcomplete():

120 t=1

121 Feedbac ck * anavtasti. getreadbac ck)

122 lo igation_t sback d 2)
123 if ‘eedbock an u%

124 (

125 a

126 E

127 tt ng 4
128

129

130

131

132

133 me navigation timeout to de

134 if uration. from, eg (Teedbiock.o nvigation_ tine) > Duration(seconds= ):
135 elf.get_logger().info( \033 * )

136 f navigator .cancelTask()

137

138 de ytion

139 if Duration. ers erat fagdlace: Pavinatten: tine), > Surstvenftecondss ):
149 «get_logger().info( '\033 \ )

141 self -goat_pub. pata (self. goal_ pose)

142 # self.get_logger ( i s\®33[8m' * ‘feedback’

143 # Do somett ng d r

144 result = se cuitaeted: raeteasutt()

145 if result == TaskResult. SUCCEEDED:

146 f .get_logger(). tnfo( )

147 msg = Bool()

148 asa cate =

149 ch_pub. publish(msg)

150 elif result == TaskResult.CANCELED:

151 Lf.get_logger().tnfo( )

152 elif “nesole == TaskResult.FAILED:

153 elf .get_logger().tnfo( )

154 else:

155 elf .get_logger().info( )

Receives and processes a navigation goal message, triggering the robot
to navigate and monitoring task status in real time. It handles timeout and

preemption, and publishes feedback based on the final result.
(@ Receive and Log the Goal
At the beginning of the function, log the received goal message.
@ Start the Navigation Task

Call self .navigator.goToPose (msg) to pass the received goal to

the navigator and initiate the robot move towards the goal point.
@ Real-Time Navigation Monitoring
Enter a while loop to continuously check whether the task is complete.

Use a counter i to throttle the frequency of feedback checking, for

30



=== Page 31 ===
Hivwoander Shenzhen Hiwonder Technology Co,Ltd

example, check every 5 iterations.

feedback = self.navigator.getFeedback (): get current

navigation feedback.

Timeout Handling: If feedback.navigation_ time exceeds 600
seconds, consider the task timed out and log "timeout...", and call

self.navigator.cancelTask() to cancel the navigation.

Preemption Handling: If the navigation time exceeds 36 seconds, log
"preempt..." and re-publish the goal via self.goal_pub with
self.goal_pose. This is often used in demo settings or to support task

preemption or switching.
@ Result Handling After Task Completion

When self.navigator.isTaskComplete() returns True, exit the
loop and retrieve the final result using result =

self.navigator.getResult().
Determine Final Outcome

If the task succeeded (TaskResult.SUCCEEDED), log "Goal succeeded!"
and publish a Bool message with value True to notify other nodes that the

goal was reached.

If the task was canceled or failed, log "Goal was canceled!" or "Goal

failed!" respectively.

If the result has an unknown status, log "Goal has an invalid return

status!".

This function implements a full navigation task workflow: receiving the
goal, initiating navigation, monitoring progress, handling timeouts or

preemption, and publishing results based on the outcome.

31


