
=== Page 1 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Lessom 4 Image Background
Segmentation

In this lesson, we will use MediaPipe's Selfie Segmentation model to separate
trained models (such as face, hand, etc.) from the background and then add a

virtual background.

1. Introduction

Firstly, import MediaPipe’s selfie segmentation model, and obtain the live
camera feed by subscribing to the topic messages. Next, perform the image
flipping processing, and drawn the segmentation map on the background
image. To improve the segmentation around the edges, apply bilateral

filtering. Finally, replace the virtual background with a virtual one.

2. Operation Steps

@ The input command should be case sensitive, and “Tab” key can be

used to complement the key words.

If you use the system image we provide, you can find the corresponding
program in the folder “3 Basic Operation Course -> 2. Introduction to

System Desktop .”

1) Power on Jetson Orin Nano board, and connect it to the remote

system desktop using NoMachine.

2) Connect it to the network. For specific operations, please refer to the
tutorials located in “3. Basic Operation Course -> 3. Network Configuration

(Wired and Wireless)” to access the network. Some models may need to be

1



=== Page 2 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

re-downloaded.

3) When entering the system desktop, drag the program file

“self_segmentation.py” under the same directory to the remote desktop.

AIT > BF v|& p

cq

1

Camera.py

face_detect.py

Fee !

face_mesh.py

“) hand.py

') mp _face_detect.py
|) mp_gesture.py

'} objectron.py

2 pose.py

"> self segmentation.py

4) Then right click on the blank area of the system desktop, and select

“Open in Terminal” to open the command-line terminal:

New Folder

Show Desktop in Files
Openin Terminal

Change Background...

Display Settings

Settings

5) Enter the following command and press Enter to run the background

segmentation detection program.

python3 self_segmentation.py

S$ python3 self_segmentation.py



=== Page 3 ===
4 IVE 5) | =e Shenzhen Hiwonder Technology Co,Ltd
6) To close the program, please use the shortcut key “Ctrl+C” to exit the

program.

3. Program Outcome

After the program starts, the frame turns into a completely gray virtual
background. When a person enters the frame, they will segmented from the

background.

MediaPipe Selfie Segmentation MediaPipe Selfie Segmentation

4. Program Analysis

@ Build a Selfie Segmentation Model

Import the selfie segmentation model from the MediaPipe toolkit.

mp.solutions.drawing utils

mp.solutions.selfie_segmentation

The first parameter “model_selection” is for model selection. MediaPipe
is available in the general model and the landscape model. Both models are
based on MobileNetV3 and have been modified to improve the efficiency. The

general model runs on a 256x256x3 (HWC) tensor and output a 256x256x1



=== Page 4 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

tensor representing the segmentation mask.

The landscape model is similar to the general model but runs ona
144x256x3 (HWC) tensor. It has fewer FLOP, making it faster than the general
model. Noted that before feeding the input image into the ML mode, MediaPipe
Selfie Segmentation automatically resizes the input image to the required

tensor dimensions.
@ Retrieve Live Camera Feed

Invoke the VideoCapture() function from cv2 library to retrieve the

camera feed.

The parameter within the function parenthesis refers to the camera

interface. You can also use “O” to access the default camera.

If the current device has only one camera connected, either “O” or “-1” can
be used as the camera ID. If multiple cameras are connected, “O” presents the

first camera, “1” represents the second camera, and so on for additional

cameras.

Convert the color space by calling the cvtColor() function from the cv2
library.

Before performing segmentation on the image, convert the image to the
RGB color space.

@ Draw the segmentation image

Based on the previously built selfie segmentation model, draw the

segmentation map of the person and the background in the image.



=== Page 5 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

@ Boundary Filtering

To improve segmentation around the edges, you can apply bilateral

filtering to results.segmentation_mask

.segmentation_mask,

np.stack((results.segmentation_mask,) * 3, axis=-1) > 0.1 — The smaller

the last parameter, the more edges are included.
@ Change Background

Remove the background from the segmentation map and replace it with a

virtual background.

Use np.zeros(image.shape, dtype=np.uint8) to remove the background
and replace it with BG COLOR. BG_COLOR can be either a color or an image.
For a color, use its RGB value; for an image, ensure its dimensions match the

camera's resolution.

@ Display the Transmitted Image

Use the imshow() function from the cv2 library to display the camera feed

in a specified window.

The first parameter inside the function’s parentheses, 'MediaPipe Selfie
Segmentation’, is the window name, and the second parameter, output_image,

is the image to be displayed.


