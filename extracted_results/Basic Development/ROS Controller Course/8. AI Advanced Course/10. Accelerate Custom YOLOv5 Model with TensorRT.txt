
=== Page 1 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd
Lesson 10 Accelerate Custom YOLOv5
Model with TensorRT

After extensive training, we obtained a new model. Proceed with
converting the new model into a version with TensorRT acceleration to improve

its performance.

1. Format Conversion

@ The input command should be case sensitive, and “Tab” key can be

used to complement the key words.

If you use the system image we provide, you can find the corresponding
program in the folder “3 Basic Operation Course -> 2. Introduction to

System Desktop .”

Additionally, if all the required environments are already installed in the image,

you can skip this step.

1) Power on Jetson Orin Nano, and connect it to NoMachine.

2) Drag the file “tensorrtx-yolov5-v7.0.zip” to the remote system

desktop:

BR

® data_gather

@ labelimg 20
EF tensorflow-2.11.0+nv23.01-cp38-cp3.... 20
EF torch-1.12.0a0+2c916ef.nv22.3-cp38-... 20
&8 torchvision-(V0.13.0) 20

® xml2yolo
id
Lensiorrtx-

a

3) Right click on a blank area of the system desktop to select “Open in

Terminal” to open a command-line terminal.



=== Page 2 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

New Folder

Show Desktop in Files

Openin Terminal

Change Background...

Display Settings

Settings

4) Enter the command to extract the file and wait for this process to

complete.

unzip tensorrtx-yolov5-v7.@.zip

S$ unzip tensorrtx-yolov5-v7.0.zip

5) Based on the location of the yolov5 folder (according to the previous

tutorial, it is stored in the ~/Desktop folder), enter the command here. You can

modify it according to the actual location of your folder.

cd Desktop/yolov5/

:~$ cd Desktop/yolovs/

6) Enter the command to copy the yolov5/gen_wts.py file from the

tensorrtx folder to the current YOLOv5 folder.

cp ~/Desktop/tensorrtx-yolov5-v7.0/yolov5/gen_wts.py .

S$ cp ~/Desktop/yolov5/runs/train

/exp4/weights/best.pt ‘
7) Enter the command and press Enter to convert the pt file to a wits file.
python3 gen_wts.py -w runs/train/exp4/weights/best.pt -o best.wts

: $ python3 gen_wts.py -w runs/tratn/exp4/weights/best.pt -o best.wts
Generating .wts for detect model
Loading runs/train/exp4/weights/best.pt

YOLOVS # 2024-2-24 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CPU

Writing into best.wts



=== Page 3 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Note: Here, we use the official yolovSn model as an example. If you need to

use a different model, simply replace yolov5n.pt in the command with the name of

your model file.

8) Then enter the command to navigate to the tensorrtx/yolov folder

cd ~/Desktop/tensorrtx-yolov5-v7.0/yolov5/

$ cd ~/Desktop/tensorrtx-yolov5-v7.0/yolovS/

9) Enter the command and press Enter to open yololayer.h file and edit it.

gedit src/config.h

: $ gedit src/config.h

10)Locate the code highlighted in the below red box. This parameter
refers to the numbers of categories for object detection. Modify the value

according to your specific needs.

Note: The value you need to enter here is the number of categories you want to
detect. You should modify it based on your specific situation. For example, if you

set 1 category when collecting data, you should enter 1 here.

12 // These are used to define input/output tensor names,
13 // you can set them to whatever you want.

14 const static char* kInputTensorName =

15 const static char* kOutputTensorName =

16

2 4 O 1 2 1 1 2
18 constexpr static int kNumClass = 1;

20 // Classfication model's number of classes
21 constexpr static int kClsNumClass = 0;
22

23 constexpr static int kBatchSize = 1;

24

25 // Yolo's input width and height must by divisible by 32
26 constexpr static int kInputH ;

27 constexpr static int kInputwW 105

28

29 // Classfication model's input shape

30 constexpr static int kClsInputH =

31 constexpr static int kClsInputwW =

32

11)After the modification completes, press the shortcut key “Ctrl+S” or



=== Page 4 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

click “Save” to save and exit the file.

12)Enter the command to create the “build” folder.
mkdir build

13)Enter the command and press Enter to navigate to the “build” folder.
cd build/

14)Enter the command and press “Enter” to compile the “build” folder.

cmake ..

- The C compiler identification is GNU 9.4.0

- The CXX compiler identification is GNU 9.4.0

- Check for working C compiler: /usr/bin/cc

- Check for working C compiler: /usr/bin/cc -- works
- Detecting C compiler ABI info

- Detecting C compiler ABI info - done

- Detecting C compile features

- Detecting C compile features - done

- Check for working CXX compiler: /usr/bin/c++

- Check for working CXX compiler: /usr/bin/c++ -- works
- Detecting CXX compiler ABI info

- Detecting CXX compiler ABI info done

- Detecting CXX compile features

- Detecting CXX compile features - done

15) Enter the command and press “Enter” to compile the contents of the

“build” folder.
make

16)Enter the command to copy the previously generated “.wts” file from

YOLOv5 to the current directory “build”:
cp ~/Desktop/yolov5/best.wts .

S$ cp ~/Desktop/yolov5

/best.wts .

17)Enter the command and press Enter to generate TensorRT model file



=== Page 5 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

“yolov5n.engine”. Then wait for the model conversion to complete.

sudo ./yolov5_det -s best.wts best.engine s

$ sudo ./yolovS det -s best.wts best.engine s
[02/24/2024 04: 28:42] [W] [TRT] The implicit batch dimension mode has been deprecated. Please create the network wi

Loading weights: best.wts
Building engine, please wait for a while...

In the command, best.wts refers to the path where the best.wts file is
located. Since you are currently in the directory where the .wts file is located,
you can simply enter the .wts file name here. best.engine is the name of the
TensorRT model file. The last parameter, ‘s’, indicates the type of model used

for training. If the model is yolov5n, you can use ‘n’ as the suffix.

18) If the command line terminal displays the following text, it indicates that

the engine file has been successfully converted.

:36:4 [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.
24-04:36:4 [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to a
4:36:4 (W] [TRT] Check verbose logs for the list of affected weights.

4:36:48 (W] [TRT] 49 weights are affected by this issue: Detected subnormal FP16 values.
24-04:36:4 (W] [TRT] 2 weights are affected by this issue: Detected values less than smallest positive FP16 subnormalJ
Build engine successfully!

2. Invoke TensorRT Model for Testing

Before start the detection, adjust and modify the configuration file as follow:
1) Access the remote desktop

2) Drag and drop the decompressed file “testimages.zip” to the remote

desktop.

® data_gather

labellmg

EF tensorflow-2.11.0+nv23.01-cp38-cp3...
@ tensorrtx-yolov5-v7.0

EF torch-1.12.0a0+2c916ef.nv22.3-cp38-...
& torchvision-(V0.13.0)

*® xmli2yolo

testimages.zip

2024/2/24 21:09




=== Page 6 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

: A
3) Double click Sy open a command-line terminal. Enter the
command to navigate to the “tensorrtx/yolov5’” file. The path should be
based on the location of your Jetson Orin Nano. Here, we refer to the

previous path.

cd ~/Desktop/tensorrtx-yolov5-v7.0/yolov5

:~$ cd ~/Desktop/tensorrtx-yolov5-v7.0/yolov5s

$

4) Enter the command to edit the parameters in the “yolov5_det_trt.py’ file.

gedit yolov5 det_trt.py

: $ gedit yolovS det_trt.py

@ Inthe script file, pay attention to the three parameters highlighted in the

red box below:
PLUGIN_LIBRARY (Dynamic library for executing detection)
engine_file_path (Path to the generated engine model)

image_dir (Path to the folder containing test images. Note that the path should

only include the image format.)



=== Page 7 ===
ry IWED i) Oo i) t Shenzhen Hiwonder Technology Co,Ltd

PLUGIN_LIBRARY
engine_file_path =

if len(sys.argv) > 1:
engine_file_path = sys.argv[1]

if len(sys.argv) > 2:
PLUGIN_LIBRARY = sys.argv[2]

ctypes.CDLL(PLUGIN_LIBRARY)
# Load coco labels
categortes = ["left"]

if os.path.exists('c
shutil.rmtree(
os.makedirs( t
# a YoLov5TRT instance
yolovS_wrapper = YoLov5TRT(engine_file_path)
try:
» yolov5_wrapper.batch_size)

image_dir
age pa 7 ; é q d e rapper.batch_size, image_dir)

Among the three parameters in the image above, fill them in according to their
actual locations. For example, in the previous tutorial, the dynamic library and
model engine file were both stored in the build folder within the current
directory. You can define and provide the test files as needed and make

changes according to your specific situation.

@ Modification of Detection Classes:

tT vcenysys-digv) > a.
PLUGIN_LIBRARY = sys.argv[2]

ctypes.CDLL(PLUGIN_LIBRARY)
# Load coco Labels

categories = ["left"]

if os.path.exists(
shutil.rmtree(

os.makedirs('output/')

# a YoLovSTRT instance

Based on the previous label categories, use left as the category in the script,
as specified in the tutorial. Ensure that it matches the labels used during the

annotation process.



=== Page 8 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

@ Modify the detection confidence: Find the parameter content highlighted
in the red box in the image below, and make the necessary modifications

and adjustments:

2@ LEN_ONE_RESULT
21

Similarly, adjust the parameter at this location based on the performance of the
trained model. For example, adjust the CONF_THRESH parameter, which
ranges from 0 to 1. Values within this range will be compared against actual
detection results; if the detection result exceeds this value, it will be recognized

as an object in the model.

After confirming the above parameters, save and exit the file, and you can

proceed with detection and recognition.

1) Enter the command to install pycuda.

pip3 install pycuda -i https://mirrors.aliyun.com/pypi/simple/

pip install pycuda -1 https://mirrors.aliyun.com/pypt/simple/

2) Enter the command, ensuring that the path in the current command

line terminal is correct.

python3 yolov5_det_trt.py

: $ python3 yolovS det_trt.py

3) Check the output result in the terminal:



=== Page 9 ===
Hivweander Shenzhen Hiwonder Technology Co,Ltd

Wwarm_up->(640, 640, 3), time->9.61ms

input->['/home/ubuntu/Desktop/testimages/7.jpg'], ti ->10.86ms, saving into output/
input->['/home/ubuntu/Desktop/testimages/6.jpg'], time->11.01ms, saving into output/
input->['/home/ubuntu/Desktop/testimages/2.jpg'], time->11.74ms, saving into output/
input->['/home/ubuntu/Desktop/testimages/5.jpg'], time->9.38ms, saving into output/

input->['/home/ubuntu/Desktop/testimages/3.jpg'], ti ->10.91ms, saving into output/
input->['/home/ubuntu/Desktop/testimages/4.jpg'], time->11.09ms, saving into output/
input->['/home/ubuntu/Desktop/testimages/1.jpg'], time->9.52ms, saving into output/

As shown in the image above, the result files for the detection are stored in the

output folder. Open it using the file explorer:

Desktop tensorrtx-yolov5-v7.0 yolov5S output +

4) View the detection results by double-clicking and opening the images
in the output folder generated in the previous step to review the detection

performance:

left:0.47

When the recognition results are unsatisfactory, adjust the detection

parameters such as CONF_THRESH. If the results are still not ideal after
adjusting the parameters, you may need to re-collect data and retrain the

model.


